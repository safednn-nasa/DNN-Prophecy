**Appication on a large Vision-Language model**

CLIP_collect_acts.ipynb: Contains code to extract activations from CLIP's VIT encoder. Inputs are images of truck and cars respectively. The labelling is done based on the zero-shot classification of CLIP.

ProphecyTool_with_CLIP.ipynb: Demonstrates application of Prophecy to extract rules using the fingerprints and zero-shot classification labels of a CLIP model trained on the RIVAL-10 dataset. 
Note: https://github.com/safednn-nasa/ProphecyPlus.git is ALIAS of https://github.com/safednn-nasa/DNN-Prophecy.git. Please clone the repository into a local folder with name ProphecyPlus, before executing the notebook.
