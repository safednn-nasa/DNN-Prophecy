{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "western-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "valued-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.models import *\n",
    "from utils.datasets import create_dataloader\n",
    "from utils.general import non_max_suppression, increment_path, check_dataset, check_img_size\n",
    "from utils.torch_utils import select_device\n",
    "from utils.metrics import ap_per_class, compute_ap\n",
    "from feature_mining.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "indirect-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "%matplotlib inline\n",
    "imgsz=1600\n",
    "imgsz_test=1600\n",
    "# img_size = (1600, 900)\n",
    "batch_size=48\n",
    "gs=64\n",
    "cache_image=True\n",
    "rect=True\n",
    "pad=0.5\n",
    "conf_thres=0.001\n",
    "iou_thres=0.6\n",
    "cfg = '../cfg/yolov4-tiny-25.cfg'\n",
    "device_str = 'cpu'\n",
    "weights='../weights/best.pt'\n",
    "data='../data/nuimages_rider.yaml'\n",
    "save_dir = Path(increment_path(Path('runs/visualize') / 'yolov4-tiny-25', exist_ok=True))  # increment run\n",
    "save_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "developed-repeat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Python version\n",
      "3.8.10 (default, Jun 22 2022, 20:18:18) \n",
      "[GCC 9.4.0]\n",
      "Version info.\n",
      "sys.version_info(major=3, minor=8, micro=10, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "import sys\n",
    "print(\"Python version\")\n",
    "print (sys.version)\n",
    "print(\"Version info.\")\n",
    "print (sys.version_info)\n",
    "assert torch.cuda.is_available(), 'CUDA unavailable, invalid device %s requested' % device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-navigator",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "formed-compilation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Darknet(\n",
       "  (module_list): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (Conv2d): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (Conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (Conv2d): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (3): FeatureConcat_l()\n",
       "    (4): Sequential(\n",
       "      (Conv2d): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (Conv2d): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (6): FeatureConcat()\n",
       "    (7): Sequential(\n",
       "      (Conv2d): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (8): FeatureConcat()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (11): FeatureConcat_l()\n",
       "    (12): Sequential(\n",
       "      (Conv2d): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (13): Sequential(\n",
       "      (Conv2d): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (14): FeatureConcat()\n",
       "    (15): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (16): FeatureConcat()\n",
       "    (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (18): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (19): FeatureConcat_l()\n",
       "    (20): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (21): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (22): FeatureConcat()\n",
       "    (23): Sequential(\n",
       "      (Conv2d): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (24): FeatureConcat()\n",
       "    (25): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (26): Sequential(\n",
       "      (Conv2d): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (27): Sequential(\n",
       "      (Conv2d): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (28): Sequential(\n",
       "      (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (29): Sequential(\n",
       "      (Conv2d): Conv2d(512, 90, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (30): YOLOLayer()\n",
       "    (31): FeatureConcat()\n",
       "    (32): Sequential(\n",
       "      (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (33): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (34): FeatureConcat()\n",
       "    (35): Sequential(\n",
       "      (Conv2d): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (36): Sequential(\n",
       "      (Conv2d): Conv2d(256, 90, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (37): YOLOLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import models\n",
    "\n",
    "# device = select_device(device_str)\n",
    "device = 'cuda:1'\n",
    "\n",
    "# Load with checkpoint\n",
    "model = Darknet(cfg).to(device)  # create model\n",
    "\n",
    "ckpt = torch.load(weights, map_location=device)  # load checkpoint\n",
    "ckpt['model'] = {k: v for k, v in ckpt['model'].items() if model.state_dict()[k].numel() == v.numel()}\n",
    "model.load_state_dict(ckpt['model'], strict=False)\n",
    "\n",
    "# Evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaafaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n",
    "_ = model(img) if device.type != 'cpu' else None  # run once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-theta",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "willing-legend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['animal', 'flat.driveable_surface', 'human.pedestrian.adult', 'human.pedestrian.child', 'human.pedestrian.construction_worker', 'human.pedestrian.personal_mobility', 'human.pedestrian.police_officer', 'human.pedestrian.stroller', 'human.pedestrian.wheelchair', 'movable_object.barrier', 'movable_object.debris', 'movable_object.pushable_pullable', 'movable_object.trafficcone', 'static_object.bicycle_rack', 'vehicle.bicycle', 'vehicle.bus.bendy', 'vehicle.bus.rigid', 'vehicle.car', 'vehicle.construction', 'vehicle.ego', 'vehicle.emergency.ambulance', 'vehicle.emergency.police', 'vehicle.motorcycle', 'vehicle.trailer', 'vehicle.truck']\n"
     ]
    }
   ],
   "source": [
    "imgsz = check_img_size(imgsz, s=64)\n",
    "imgsz_test = check_img_size(imgsz_test, s=64)\n",
    "\n",
    "with open(data) as f:\n",
    "    data_dict = yaml.load(f, Loader=yaml.FullLoader)  # data dict\n",
    "\n",
    "check_dataset(data_dict)  # check    \n",
    "withrider_path = data_dict['with_rider']\n",
    "withoutrider_path = data_dict['without_rider']\n",
    "other_path = data_dict['other']\n",
    "nc, names = (int(data_dict['nc']), data_dict['names'])  # number classes, names\n",
    "assert len(names) == nc, '%g names found for nc=%g dataset in %s' % (len(names), nc, opt.data)  # check\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "front-copyright",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning labels /root/data/nuimages/labels/samples/CAM_BACK.cache3 (1092 found, 0 missing, 0 empty, 0 duplicate, for 1092 images): 1092it [00:00, 10647.15it/s]\n"
     ]
    }
   ],
   "source": [
    "withloader, withset = create_dataloader(withrider_path, imgsz, batch_size, gs)\n",
    "mlc = np.concatenate(withset.labels, 0)[:, 0].max()  # max label class\n",
    "nb = len(withloader)  # number of batches\n",
    "assert mlc < nc, 'Label class %g exceeds nc=%g in %s. Possible class labels are 0-%g' % (mlc, nc, data, nc - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "current-whole",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning images: 100%|██████████| 3141/3141 [00:40<00:00, 78.12it/s] \n",
      "Scanning labels /root/data/nuimages/labels/samples/CAM_BACK.cache3 (3141 found, 0 missing, 0 empty, 0 duplicate, for 3141 images): 3141it [00:00, 8271.82it/s]\n"
     ]
    }
   ],
   "source": [
    "withoutloader, withoutset = create_dataloader(withoutrider_path, imgsz_test, batch_size, gs, rect=True, pad=pad)  # testloader\n",
    "nb1 = len(withoutloader)  # number of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "seven-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning images: 100%|██████████| 9831/9831 [01:27<00:00, 112.06it/s]\n",
      "Scanning labels /root/data/nuimages/labels/samples/CAM_BACK.cache3 (9822 found, 0 missing, 9 empty, 0 duplicate, for 9831 images): 9831it [00:01, 8652.63it/s]\n"
     ]
    }
   ],
   "source": [
    "otherloader, otherset = create_dataloader(other_path, imgsz_test, batch_size, gs, rect=True, pad=pad)  # testloader\n",
    "nb2 = len(otherloader)  # number of batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-representation",
   "metadata": {},
   "source": [
    "### Predict Using Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02ca7e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.00000e+00, 1.70000e+01, 7.64375e-01, 5.10937e-01, 1.87499e-02, 1.43752e-02],\n",
      "        [0.00000e+00, 1.70000e+01, 9.41875e-01, 5.19063e-01, 7.62499e-02, 3.81251e-02],\n",
      "        [0.00000e+00, 1.70000e+01, 9.82812e-01, 5.22500e-01, 3.43749e-02, 3.87500e-02],\n",
      "        ...,\n",
      "        [4.70000e+01, 1.70000e+01, 6.22500e-01, 5.16875e-01, 6.37500e-02, 4.50000e-02],\n",
      "        [4.70000e+01, 1.70000e+01, 7.88125e-01, 5.58125e-01, 1.53750e-01, 1.17500e-01],\n",
      "        [4.70000e+01, 2.20000e+01, 6.99063e-01, 5.00313e-01, 9.37492e-03, 1.81249e-02]])\n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(withloader)):\n",
    "    print(targets)\n",
    "    print(img.shape[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fossil-asian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:28<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(withloader)):\n",
    "    img = img.to(device, non_blocking=True)\n",
    "    img = img.float()  # uint8 to fp16/32\n",
    "    img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    targets = targets.to(device)\n",
    "    nb, _, height, width = img.shape  # batch size, channels, height, width\n",
    "    with torch.no_grad():\n",
    "        inf_out = model(img)[0]\n",
    "        output = non_max_suppression(inf_out, conf_thres=conf_thres, iou_thres=iou_thres)\n",
    "        accumulate_stats(stats, output, targets, nc, device, height, width)\n",
    "stats = [np.concatenate(x, 0) for x in zip(*stats)]  # to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50f61b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, ap, f1, ap_class = ap_per_class(*stats, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "71974fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class                               \tPricision@0.1\tRecall@0.1\tmAP for class\n",
      "animal                              \t0.0000000000\t0.0000000000\t0.0162473876\n",
      "human.pedestrian.adult              \t0.4236908130\t0.7513051732\t0.3816287376\n",
      "human.pedestrian.child              \t0.1282785065\t0.0666666667\t0.0301323538\n",
      "human.pedestrian.construction_worker\t0.3343596420\t0.6971153846\t0.2828143693\n",
      "human.pedestrian.personal_mobility  \t0.1718048425\t0.3571428571\t0.1360895316\n",
      "human.pedestrian.police_officer     \t0.0000000000\t0.0000000000\t0.0108555106\n",
      "human.pedestrian.stroller           \t0.4405753237\t0.7500000000\t0.3715889199\n",
      "human.pedestrian.wheelchair         \t0.0000000000\t0.0000000000\t0.0000000000\n",
      "movable_object.barrier              \t0.3981260938\t0.8001917774\t0.4278869516\n",
      "movable_object.debris               \t0.0894851512\t0.2121212121\t0.0534920449\n",
      "movable_object.pushable_pullable    \t0.3092030145\t0.7187500000\t0.2375867268\n",
      "movable_object.trafficcone          \t0.4425842061\t0.7648839556\t0.4014044837\n",
      "static_object.bicycle_rack          \t0.2628646485\t0.6875000000\t0.1599937941\n",
      "vehicle.bicycle                     \t0.4912977814\t0.7172774869\t0.4928436602\n",
      "vehicle.bus.bendy                   \t0.0000000000\t0.0000000000\t0.0107005495\n",
      "vehicle.bus.rigid                   \t0.4740362219\t0.7428571429\t0.5062358768\n",
      "vehicle.car                         \t0.5530379436\t0.9055258467\t0.6186581804\n",
      "vehicle.construction                \t0.2838657680\t0.6129032258\t0.2188181084\n",
      "vehicle.emergency.police            \t0.0000000000\t0.0000000000\t0.0000000000\n",
      "vehicle.motorcycle                  \t0.7005378943\t0.8993902439\t0.6312347454\n",
      "vehicle.trailer                     \t0.3033943858\t0.4285714286\t0.1467762911\n",
      "vehicle.truck                       \t0.4311558830\t0.8068376068\t0.5005979142\n",
      "\n",
      "Class                               \tAP@0.5:0.95\n",
      "animal                              \t0.042919  0.029889  0.029889  0.029889  0.029889  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "human.pedestrian.adult              \t0.691929  0.655916  0.607697  0.551234  0.470013  0.381986  0.269629  0.143485  0.041044  0.003356  \n",
      "human.pedestrian.child              \t0.044207  0.044207  0.038828  0.038828  0.038828  0.038828  0.037516  0.018861  0.000611  0.000611  \n",
      "human.pedestrian.construction_worker\t0.641668  0.581818  0.511293  0.449420  0.321082  0.188026  0.090531  0.032700  0.011607  0.000000  \n",
      "human.pedestrian.personal_mobility  \t0.233156  0.233156  0.226371  0.214782  0.155663  0.122617  0.122617  0.025810  0.025810  0.000913  \n",
      "human.pedestrian.police_officer     \t0.018722  0.018722  0.018722  0.018722  0.018722  0.005859  0.004542  0.004542  0.000000  0.000000  \n",
      "human.pedestrian.stroller           \t0.745712  0.745712  0.745712  0.495940  0.245703  0.245703  0.245703  0.245703  0.000000  0.000000  \n",
      "human.pedestrian.wheelchair         \t0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "movable_object.barrier              \t0.727669  0.680345  0.628277  0.569943  0.507519  0.441721  0.353585  0.242966  0.113904  0.012941  \n",
      "movable_object.debris               \t0.101073  0.097560  0.090795  0.090156  0.090156  0.032215  0.026369  0.005402  0.001195  0.000000  \n",
      "movable_object.pushable_pullable    \t0.470067  0.436684  0.390945  0.293016  0.238851  0.231867  0.141149  0.101277  0.064721  0.007290  \n",
      "movable_object.trafficcone          \t0.709027  0.674944  0.632828  0.577162  0.483031  0.384854  0.288866  0.175873  0.081634  0.005827  \n",
      "static_object.bicycle_rack          \t0.441518  0.414935  0.297171  0.176196  0.110222  0.109873  0.046457  0.003566  0.000000  0.000000  \n",
      "vehicle.bicycle                     \t0.708099  0.672954  0.661053  0.643172  0.604936  0.577356  0.529098  0.370045  0.138036  0.023686  \n",
      "vehicle.bus.bendy                   \t0.014481  0.014481  0.014481  0.014481  0.014481  0.014481  0.005030  0.005030  0.005030  0.005030  \n",
      "vehicle.bus.rigid                   \t0.712141  0.697070  0.657956  0.645600  0.604116  0.577630  0.503792  0.410248  0.228181  0.025625  \n",
      "vehicle.car                         \t0.882757  0.860708  0.827848  0.786424  0.732755  0.665745  0.576391  0.463756  0.305588  0.084610  \n",
      "vehicle.construction                \t0.518166  0.470361  0.404120  0.344650  0.224189  0.131937  0.063275  0.021070  0.009238  0.001174  \n",
      "vehicle.emergency.police            \t0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "vehicle.motorcycle                  \t0.908230  0.890592  0.868296  0.831937  0.786034  0.726142  0.607469  0.443550  0.230794  0.019304  \n",
      "vehicle.trailer                     \t0.376885  0.259526  0.230543  0.223696  0.147026  0.110581  0.082518  0.036987  0.000000  0.000000  \n",
      "vehicle.truck                       \t0.754924  0.734158  0.699453  0.657483  0.610575  0.538407  0.444349  0.344843  0.186848  0.034940  \n",
      "\n",
      "Mean Pricision\tMean Recall\tmAP       \n",
      "0.2835590054\t0.4963200004\t0.2561630063\n"
     ]
    }
   ],
   "source": [
    "unique_classes = np.unique(stats[3])\n",
    "print('{:<36}\\t{:<10}\\t{:<10}\\t{:<10}'.format('Class', 'Pricision@0.1', 'Recall@0.1', 'mAP for class'))\n",
    "for i, cls in enumerate(unique_classes):\n",
    "    print('{:<36}\\t{:.10f}\\t{:.10f}\\t{:.10f}'.format(names[int(cls)], p[i][0], r[i][0], np.mean(ap[i])) )\n",
    "\n",
    "print()\n",
    "\n",
    "print('{:<36}\\t{:<10}'.format('Class', 'AP@0.5:0.95'))\n",
    "for i, cls in enumerate(unique_classes):\n",
    "    print('{:<36}\\t'.format(names[int(cls)]), end='')\n",
    "    for j in ap[i]:\n",
    "        print('{:5f}  '.format(j), end='')\n",
    "    print()\n",
    "\n",
    "print()\n",
    "print('{:<10}\\t{:<10}\\t{:<10}'.format('Mean Pricision', 'Mean Recall', 'mAP'))\n",
    "print('{:.10f}\\t{:.10f}\\t{:.10f}'.format(np.mean(p[:,0]), np.mean(r[:,0]), np.mean(ap)) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94a30f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76229447",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats1 = []\n",
    "for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(withoutloader)):\n",
    "    img = img.to(device, non_blocking=True)\n",
    "    img = img.float()  # uint8 to fp16/32\n",
    "    img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    targets = targets.to(device)\n",
    "    nb, _, height, width = img.shape  # batch size, channels, height, width\n",
    "    with torch.no_grad():\n",
    "        inf_out = model(img)[0]\n",
    "        output = non_max_suppression(inf_out, conf_thres=conf_thres, iou_thres=iou_thres)\n",
    "        accumulate_stats(stats1, output, targets, nc, device, height, width)\n",
    "stats1 = [np.concatenate(x, 0) for x in zip(*stats1)]  # to numpy\n",
    "\n",
    "p1, r1, ap1, f11, ap_class1 = ap_per_class(*stats1, plot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "15c0fce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class                               \tPricision@0.1\tRecall@0.1\tmAP for class\n",
      "animal                              \t0.0000000000\t0.0000000000\t0.0392087073\n",
      "human.pedestrian.adult              \t0.4719564612\t0.7711167086\t0.4158139107\n",
      "human.pedestrian.child              \t0.0768364838\t0.0322580645\t0.0079519900\n",
      "human.pedestrian.construction_worker\t0.3555503417\t0.6106382979\t0.2669061393\n",
      "human.pedestrian.personal_mobility  \t0.3471502881\t0.7364532020\t0.1864432467\n",
      "human.pedestrian.police_officer     \t0.0000000000\t0.0000000000\t0.0871143010\n",
      "human.pedestrian.stroller           \t0.4306182035\t0.3125000000\t0.2233681258\n",
      "human.pedestrian.wheelchair         \t0.0000000000\t0.0000000000\t0.0000000000\n",
      "movable_object.barrier              \t0.4450960625\t0.8094599128\t0.4559263467\n",
      "movable_object.debris               \t0.1571745852\t0.2894303385\t0.0705275874\n",
      "movable_object.pushable_pullable    \t0.3162797122\t0.5207100592\t0.2127787803\n",
      "movable_object.trafficcone          \t0.5201519425\t0.8297872340\t0.4781892598\n",
      "static_object.bicycle_rack          \t0.2024533318\t0.6813186813\t0.1786179924\n",
      "vehicle.bicycle                     \t0.6377117055\t0.8262068966\t0.5261032459\n",
      "vehicle.bus.bendy                   \t0.0000000000\t0.0000000000\t0.0097855851\n",
      "vehicle.bus.rigid                   \t0.4294212100\t0.6645161290\t0.4147711031\n",
      "vehicle.car                         \t0.5786429813\t0.8932411674\t0.6169426495\n",
      "vehicle.construction                \t0.2710001235\t0.6327683616\t0.2214506502\n",
      "vehicle.emergency.ambulance         \t0.0000000000\t0.0000000000\t0.0000000000\n",
      "vehicle.emergency.police            \t0.0000000000\t0.0000000000\t0.0000000000\n",
      "vehicle.motorcycle                  \t0.5239158424\t0.8314301251\t0.4638015496\n",
      "vehicle.trailer                     \t0.2292046402\t0.3725490196\t0.1070901652\n",
      "vehicle.truck                       \t0.4299581908\t0.7717879605\t0.4647988146\n",
      "\n",
      "Class                               \tAP@0.5:0.95\n",
      "animal                              \t0.083806  0.083806  0.083806  0.060070  0.060070  0.020530  0.000000  0.000000  0.000000  0.000000  \n",
      "human.pedestrian.adult              \t0.739263  0.702860  0.659699  0.604948  0.519845  0.415335  0.295322  0.166271  0.051616  0.002979  \n",
      "human.pedestrian.child              \t0.018371  0.014681  0.012632  0.009203  0.008989  0.005961  0.004613  0.003931  0.001138  0.000000  \n",
      "human.pedestrian.construction_worker\t0.534469  0.492446  0.439341  0.400088  0.329986  0.249310  0.136294  0.070092  0.016843  0.000193  \n",
      "human.pedestrian.personal_mobility  \t0.520142  0.450732  0.359165  0.249597  0.154542  0.084733  0.029848  0.009600  0.006074  0.000000  \n",
      "human.pedestrian.police_officer     \t0.110561  0.110561  0.110561  0.110561  0.110069  0.110069  0.106069  0.098202  0.004491  0.000000  \n",
      "human.pedestrian.stroller           \t0.352065  0.352065  0.349942  0.343877  0.316082  0.316082  0.170773  0.032795  0.000000  0.000000  \n",
      "human.pedestrian.wheelchair         \t0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "movable_object.barrier              \t0.750158  0.710138  0.663655  0.605545  0.547792  0.477012  0.389667  0.271226  0.127688  0.016383  \n",
      "movable_object.debris               \t0.142432  0.131446  0.120738  0.097731  0.079900  0.050881  0.038939  0.031664  0.011261  0.000285  \n",
      "movable_object.pushable_pullable    \t0.403301  0.386565  0.344447  0.292767  0.264010  0.203181  0.143679  0.069866  0.014736  0.005236  \n",
      "movable_object.trafficcone          \t0.806020  0.774099  0.728004  0.670524  0.597421  0.495519  0.365905  0.226722  0.106234  0.011445  \n",
      "static_object.bicycle_rack          \t0.385334  0.339478  0.306549  0.267898  0.221846  0.149587  0.080644  0.030768  0.003992  0.000086  \n",
      "vehicle.bicycle                     \t0.833051  0.809288  0.777207  0.728222  0.668961  0.580184  0.446184  0.294359  0.116010  0.007568  \n",
      "vehicle.bus.bendy                   \t0.016493  0.016493  0.016493  0.011055  0.011055  0.009580  0.008208  0.003478  0.003478  0.001525  \n",
      "vehicle.bus.rigid                   \t0.625945  0.597776  0.571392  0.537991  0.514426  0.459050  0.374580  0.273411  0.166322  0.026817  \n",
      "vehicle.car                         \t0.880757  0.859919  0.833142  0.794785  0.738863  0.663919  0.573140  0.452149  0.288060  0.084692  \n",
      "vehicle.construction                \t0.531656  0.458588  0.414023  0.331710  0.220690  0.133711  0.072143  0.036611  0.015375  0.000000  \n",
      "vehicle.emergency.ambulance         \t0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "vehicle.emergency.police            \t0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "vehicle.motorcycle                  \t0.818995  0.772908  0.718229  0.661680  0.587378  0.464965  0.332024  0.207984  0.069647  0.004206  \n",
      "vehicle.trailer                     \t0.264904  0.237957  0.188196  0.149188  0.111532  0.082136  0.036580  0.000204  0.000204  0.000000  \n",
      "vehicle.truck                       \t0.707372  0.687748  0.657923  0.621137  0.571758  0.504955  0.415423  0.304679  0.157356  0.019638  \n",
      "\n",
      "Mean Pricision\tMean Recall\tmAP       \n",
      "0.2792661785\t0.4602683547\t0.2368517457\n"
     ]
    }
   ],
   "source": [
    "unique_classes = np.unique(stats1[3])\n",
    "print('{:<36}\\t{:<10}\\t{:<10}\\t{:<10}'.format('Class', 'Pricision@0.1', 'Recall@0.1', 'mAP for class'))\n",
    "for i, cls in enumerate(unique_classes):\n",
    "    print('{:<36}\\t{:.10f}\\t{:.10f}\\t{:.10f}'.format(names[int(cls)], p1[i][0], r1[i][0], np.mean(ap1[i])) )\n",
    "\n",
    "print()\n",
    "\n",
    "print('{:<36}\\t{:<10}'.format('Class', 'AP@0.5:0.95'))\n",
    "for i, cls in enumerate(unique_classes):\n",
    "    print('{:<36}\\t'.format(names[int(cls)]), end='')\n",
    "    for j in ap1[i]:\n",
    "        print('{:5f}  '.format(j), end='')\n",
    "    print()\n",
    "\n",
    "print()\n",
    "print('{:<10}\\t{:<10}\\t{:<10}'.format('Mean Pricision', 'Mean Recall', 'mAP'))\n",
    "print('{:.10f}\\t{:.10f}\\t{:.10f}'.format(np.mean(p1[:,0]), np.mean(r1[:,0]), np.mean(ap1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d342f1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e9fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2 = []\n",
    "for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(otherloader)):\n",
    "    img = img.to(device, non_blocking=True)\n",
    "    img = img.float()  # uint8 to fp16/32\n",
    "    img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    targets = targets.to(device)\n",
    "    nb, _, height, width = img.shape  # batch size, channels, height, width\n",
    "    with torch.no_grad():\n",
    "        inf_out = model(img)[0]\n",
    "        output = non_max_suppression(inf_out, conf_thres=conf_thres, iou_thres=iou_thres)\n",
    "        accumulate_stats(stats2, output, targets, nc, device, height, width)\n",
    "stats2 = [np.concatenate(x, 0) for x in zip(*stats2)]  # to numpy\n",
    "\n",
    "p2, r2, ap2, f12, ap_class2 = ap_per_class(*stats2, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eab64cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class                               \tPricision@0.1\tRecall@0.1\tmAP for class\n",
      "animal                              \t0.0000000000\t0.0000000000\t0.0120988171\n",
      "human.pedestrian.adult              \t0.4933997453\t0.7779603625\t0.4173183529\n",
      "human.pedestrian.child              \t0.1603157216\t0.1071428571\t0.0282696817\n",
      "human.pedestrian.construction_worker\t0.3861860690\t0.6338266385\t0.2803426276\n",
      "human.pedestrian.police_officer     \t0.0000000000\t0.0000000000\t0.0299396035\n",
      "human.pedestrian.stroller           \t0.5346809532\t0.2857142857\t0.1658604040\n",
      "movable_object.barrier              \t0.4310119606\t0.7902807074\t0.4379173301\n",
      "movable_object.debris               \t0.1983619771\t0.2938931298\t0.0633600352\n",
      "movable_object.pushable_pullable    \t0.2502778847\t0.4565826331\t0.1539829404\n",
      "movable_object.trafficcone          \t0.5430291919\t0.8364452680\t0.4902008302\n",
      "static_object.bicycle_rack          \t0.3744589784\t0.6993019664\t0.2540254498\n",
      "vehicle.bicycle                     \t0.0018435699\t0.5000000000\t0.0008012618\n",
      "vehicle.bus.bendy                   \t0.0000000000\t0.0000000000\t0.0094423831\n",
      "vehicle.bus.rigid                   \t0.3935238541\t0.6623164763\t0.3905768480\n",
      "vehicle.car                         \t0.5588593022\t0.8893531321\t0.6048790754\n",
      "vehicle.construction                \t0.3371261471\t0.6707818930\t0.2570609787\n",
      "vehicle.emergency.ambulance         \t0.0000000000\t0.0000000000\t0.0000000000\n",
      "vehicle.emergency.police            \t0.0000000000\t0.0000000000\t0.0006953892\n",
      "vehicle.trailer                     \t0.2674594577\t0.3341584158\t0.1031424407\n",
      "vehicle.truck                       \t0.4179315122\t0.7228605388\t0.4216458323\n",
      "\n",
      "Class                               \tAP@0.5:0.95\n",
      "animal                              \t0.027489  0.022521  0.020872  0.016298  0.015435  0.015435  0.002938  0.000000  0.000000  0.000000  \n",
      "human.pedestrian.adult              \t0.747536  0.713893  0.665764  0.602500  0.520429  0.415071  0.292320  0.159428  0.052708  0.003535  \n",
      "human.pedestrian.child              \t0.057808  0.051413  0.043164  0.039008  0.034181  0.026475  0.018388  0.011320  0.000630  0.000310  \n",
      "human.pedestrian.construction_worker\t0.566477  0.523166  0.476141  0.415398  0.338978  0.247142  0.153845  0.068068  0.012896  0.001315  \n",
      "human.pedestrian.police_officer     \t0.042396  0.042396  0.041946  0.041696  0.039299  0.035442  0.029472  0.019173  0.007286  0.000292  \n",
      "human.pedestrian.stroller           \t0.343575  0.304101  0.301040  0.290653  0.253816  0.102040  0.046929  0.015123  0.001327  0.000000  \n",
      "movable_object.barrier              \t0.726649  0.684655  0.635641  0.579976  0.523666  0.455165  0.373330  0.260201  0.126001  0.013888  \n",
      "movable_object.debris               \t0.152056  0.134156  0.116770  0.096154  0.069092  0.041923  0.019842  0.003164  0.000415  0.000027  \n",
      "movable_object.pushable_pullable    \t0.304615  0.272169  0.251275  0.223768  0.176125  0.137733  0.091163  0.060798  0.021255  0.000929  \n",
      "movable_object.trafficcone          \t0.814247  0.779598  0.738390  0.682666  0.606056  0.509455  0.385957  0.253460  0.115038  0.017140  \n",
      "static_object.bicycle_rack          \t0.544570  0.486145  0.428376  0.376164  0.309968  0.214111  0.117603  0.053814  0.009077  0.000428  \n",
      "vehicle.bicycle                     \t0.001996  0.001996  0.001996  0.000506  0.000506  0.000506  0.000506  0.000000  0.000000  0.000000  \n",
      "vehicle.bus.bendy                   \t0.016920  0.014798  0.012027  0.011111  0.010452  0.009443  0.009443  0.007908  0.002003  0.000319  \n",
      "vehicle.bus.rigid                   \t0.601952  0.568788  0.542585  0.513109  0.476861  0.416467  0.353884  0.267576  0.144668  0.019879  \n",
      "vehicle.car                         \t0.869887  0.847487  0.817368  0.776016  0.723207  0.654253  0.563185  0.440653  0.283115  0.073620  \n",
      "vehicle.construction                \t0.579561  0.524896  0.453182  0.366833  0.287605  0.191303  0.114016  0.045192  0.007147  0.000874  \n",
      "vehicle.emergency.ambulance         \t0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "vehicle.emergency.police            \t0.000773  0.000773  0.000773  0.000773  0.000773  0.000773  0.000773  0.000773  0.000773  0.000000  \n",
      "vehicle.trailer                     \t0.237001  0.203882  0.173885  0.143666  0.115059  0.083797  0.039682  0.028007  0.006321  0.000125  \n",
      "vehicle.truck                       \t0.656773  0.632661  0.602888  0.564101  0.518540  0.453822  0.368457  0.266112  0.136183  0.016920  \n",
      "\n",
      "Mean Pricision\tMean Recall\tmAP       \n",
      "0.2674233163\t0.4330309152\t0.2060780141\n"
     ]
    }
   ],
   "source": [
    "unique_classes = np.unique(stats2[3])\n",
    "print('{:<36}\\t{:<10}\\t{:<10}\\t{:<10}'.format('Class', 'Pricision@0.1', 'Recall@0.1', 'mAP for class'))\n",
    "for i, cls in enumerate(unique_classes):\n",
    "    print('{:<36}\\t{:.10f}\\t{:.10f}\\t{:.10f}'.format(names[int(cls)], p2[i][0], r2[i][0], np.mean(ap2[i])) )\n",
    "\n",
    "print()\n",
    "\n",
    "print('{:<36}\\t{:<10}'.format('Class', 'AP@0.5:0.95'))\n",
    "for i, cls in enumerate(unique_classes):\n",
    "    print('{:<36}\\t'.format(names[int(cls)]), end='')\n",
    "    for j in ap2[i]:\n",
    "        print('{:5f}  '.format(j), end='')\n",
    "    print()\n",
    "    \n",
    "print()\n",
    "print('{:<10}\\t{:<10}\\t{:<10}'.format('Mean Pricision', 'Mean Recall', 'mAP'))\n",
    "print('{:.10f}\\t{:.10f}\\t{:.10f}'.format(np.mean(p2[:,0]), np.mean(r2[:,0]), np.mean(ap2)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e189b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 13 22:03:41 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN RTX    Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 41%   36C    P2    53W / 280W |  23790MiB / 24219MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN RTX    Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 41%   34C    P8    15W / 280W |      4MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA TITAN X ...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 23%   29C    P8     8W / 250W |      4MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11427011",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:2'\n",
    "p, r, ap, f1, ap_class, raw_stats, path =  mAP_dataset(model, withloader, device, names, nc, conf_thres, iou_thres)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
