{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**INSTALLATION**"
      ],
      "metadata": {
        "id": "OVxrtSIXXuv0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bKcRdNC2sBR",
        "outputId": "7cbfd594-2b83-4203-9c24-9debef01add1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ProphecyPlus' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone --recurse-submodules https://github.com/safednn-nasa/ProphecyPlus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_mx5eC_3XLz",
        "outputId": "83be38b4-7538-43e1-c375-28ca8f0fc532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ProphecyPlus\n",
            "/content/ProphecyPlus\n",
            "total 15096\n",
            "-rw-r--r-- 1 root root   940648 Jan  1 02:10 mnist_cnn.h5\n",
            "-rw-r--r-- 1 root root       38 Jan  1 02:10 readme.txt\n",
            "-rw-r--r-- 1 root root 14250974 Jan  1 02:10 mnist.zip\n",
            "-rw-r--r-- 1 root root   237800 Jan  1 02:10 cnn_max_mnist2.h5\n",
            "-rw-r--r-- 1 root root    12850 Jan  1 02:10 inp_arr_acts.csv\n"
          ]
        }
      ],
      "source": [
        "%cd ./ProphecyPlus\n",
        "!pwd\n",
        "!ls -lt dataset_models/airfoil_self_noise/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aD6Pxkus2x1w",
        "outputId": "105a4509-dbd4-4615-8f0a-0a6b48a8d38b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy~=1.23.5 (from -r requirements.txt (line 1))\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting pandas~=1.3.5 (from -r requirements.txt (line 2))\n",
            "  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting scikit-learn~=1.3.0 (from -r requirements.txt (line 3))\n",
            "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scipy~=1.9.3 (from -r requirements.txt (line 4))\n",
            "  Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow~=2.14.0 (from -r requirements.txt (line 5))\n",
            "  Downloading tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting keras~=2.14.0 (from -r requirements.txt (line 6))\n",
            "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pybind11~=2.11.1 (from -r requirements.txt (line 7))\n",
            "  Downloading pybind11-2.11.2-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting tqdm~=4.66.1 (from -r requirements.txt (line 8))\n",
            "  Downloading tqdm-4.66.6-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas~=1.3.5->-r requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas~=1.3.5->-r requirements.txt (line 2)) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn~=1.3.0->-r requirements.txt (line 3)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn~=1.3.0->-r requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->-r requirements.txt (line 5)) (1.68.1)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow~=2.14.0->-r requirements.txt (line 5))\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow~=2.14.0->-r requirements.txt (line 5))\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.14.0->-r requirements.txt (line 5)) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->-r requirements.txt (line 5)) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->-r requirements.txt (line 5))\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->-r requirements.txt (line 5)) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->-r requirements.txt (line 5)) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->-r requirements.txt (line 5)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->-r requirements.txt (line 5)) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->-r requirements.txt (line 5)) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->-r requirements.txt (line 5)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->-r requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->-r requirements.txt (line 5)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->-r requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->-r requirements.txt (line 5)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->-r requirements.txt (line 5)) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->-r requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->-r requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->-r requirements.txt (line 5)) (3.2.2)\n",
            "Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.9/489.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.11.2-py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.3/229.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: tqdm, tensorflow-estimator, pybind11, numpy, keras, scipy, pandas, scikit-learn, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.0\n",
            "    Uninstalling scikit-learn-1.6.0:\n",
            "      Successfully uninstalled scikit-learn-1.6.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.88 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.3.5 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.4.33 requires scipy>=1.10, but you have scipy 1.9.3 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.4.33 requires scipy>=1.10, but you have scipy 1.9.3 which is incompatible.\n",
            "scikit-image 0.25.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.0 requires scipy>=1.11.2, but you have scipy 1.9.3 which is incompatible.\n",
            "tensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.14.1 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-1.0.0 keras-2.14.0 numpy-1.23.5 pandas-1.3.5 pybind11-2.11.2 scikit-learn-1.3.2 scipy-1.9.3 tensorboard-2.14.1 tensorflow-2.14.1 tensorflow-estimator-2.14.0 tqdm-4.66.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "44a318732fbb4cfdb7221466dffb05b6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOAD DATA**"
      ],
      "metadata": {
        "id": "NCIpSDjtvTkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data = np.genfromtxt(\"/content/ProphecyPlus/dataset_models/airfoil_self_noise/airfoil_self_noise.csv\", delimiter=',')\n",
        "print(data.shape)\n",
        "\n",
        "inputstr = data[:,0:5]\n",
        "outputstr = data[:,5]\n",
        "print(inputstr.shape)\n",
        "print(inputstr[0])\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "for indx in range(0, len(inputstr)):\n",
        "  input = []\n",
        "  for indx1 in range(0, len(inputstr[indx])):\n",
        "    val = np.float32(inputstr[indx][indx1])\n",
        "    input.append(val)\n",
        "    if (indx == 0):\n",
        "      print(type(val), val)\n",
        "      print(input)\n",
        "  inputs.append(input)\n",
        "  outputs.append(np.float32(outputstr[indx]))\n",
        "\n",
        "print(inputs[0])\n",
        "print(outputs[0])\n",
        "\n",
        "def z_score_normalize(data):\n",
        "    \"\"\"\n",
        "    Applies z-score normalization (subtracts mean, divides by standard deviation) to the input data.\n",
        "\n",
        "    Args:\n",
        "        data (numpy.ndarray): The data to be normalized. Each row is a sample, and each column is a feature.\n",
        "\n",
        "    Returns:\n",
        "        normalized_data (numpy.ndarray): The normalized data.\n",
        "        mean (numpy.ndarray): The mean of the original data (per feature).\n",
        "        std (numpy.ndarray): The standard deviation of the original data (per feature).\n",
        "    \"\"\"\n",
        "    # Convert data to NumPy array if it's a list\n",
        "    data = np.asarray(data)\n",
        "\n",
        "    mean = np.mean(data, axis=0)\n",
        "    std = np.std(data, axis=0)\n",
        "\n",
        "    # Avoid division by zero\n",
        "    # Check if std is a scalar (for 1D data)\n",
        "    if np.isscalar(std):\n",
        "        if std == 0:\n",
        "            std = 1\n",
        "    else:  # For 2D data (or higher)\n",
        "        std[std == 0] = 1\n",
        "\n",
        "    normalized_data = (data - mean) / std\n",
        "    return normalized_data, mean, std\n",
        "\n",
        "(normalized_data, mean, std)= z_score_normalize(inputs)\n",
        "print(normalized_data[0])\n",
        "(normalized_output, mean, std)= z_score_normalize(outputs)\n",
        "print(normalized_output[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtWiGSFS5Ibe",
        "outputId": "cc714598-e260-4f1b-d71f-46423a629bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1503, 6)\n",
            "(1503, 5)\n",
            "[8.00000e+02 0.00000e+00 3.04800e-01 7.13000e+01 2.66337e-03]\n",
            "<class 'numpy.float32'> 800.0\n",
            "[800.0]\n",
            "<class 'numpy.float32'> 0.0\n",
            "[800.0, 0.0]\n",
            "<class 'numpy.float32'> 0.3048\n",
            "[800.0, 0.0, 0.3048]\n",
            "<class 'numpy.float32'> 71.3\n",
            "[800.0, 0.0, 0.3048, 71.3]\n",
            "<class 'numpy.float32'> 0.00266337\n",
            "[800.0, 0.0, 0.3048, 71.3, 0.00266337]\n",
            "[800.0, 0.0, 0.3048, 71.3, 0.00266337]\n",
            "126.201\n",
            "[-0.6620218 -1.1463989  1.7992973  1.312917  -0.6448043]\n",
            "0.1979379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOAD ONNX AND H5 MODELS**"
      ],
      "metadata": {
        "id": "oyeeofP-wLYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install onnx\n",
        "! pip install onnx-tf\n",
        "\n",
        "! pip install pybind11\n",
        "! pip install cmake\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "import onnx\n",
        "!pip install onnxruntime\n",
        "import onnxruntime"
      ],
      "metadata": {
        "id": "9qSN2Q0vwiL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session = onnxruntime.InferenceSession(\"/content/ProphecyPlus/dataset_models/airfoil_self_noise/renamed_model.onnx\", None)\n",
        "input_name = session.get_inputs()[0].name\n",
        "output_name = session.get_outputs()[0].name\n",
        "print(input_name)\n",
        "print(output_name)\n",
        "\n",
        "\n",
        "results = []\n",
        "for indx in range(0,len(normalized_data)):\n",
        "  input_data = (normalized_data[indx]).reshape(1, -1).astype(np.float32)\n",
        "  result = session.run([output_name], {input_name: input_data})\n",
        "  results.append(result[0][0][0])\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "print(np.shape(results), np.shape(outputs))\n",
        "r2 = r2_score(results,normalized_output)\n",
        "print(\"R2 Score:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGyU8ejelk9J",
        "outputId": "2d057e03-f4f9-4714-906c-074220ed609e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer_0_input_0\n",
            "layer_6_output_0\n",
            "(1503,) (1503,)\n",
            "R2 Score: 0.8916182518005371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "\n",
        "print('Loading the model:')\n",
        "model_h5=tf.keras.models.load_model(\"/content/ProphecyPlus/dataset_models/airfoil_self_noise/model.h5\")\n",
        "print(\"Printing summary of the model:\")\n",
        "model_h5.summary()\n",
        "\n",
        "    # Get predictions\n",
        "results_h5_train = model_h5.predict(normalized_data_train)\n",
        "print(np.shape(results_h5_train), np.shape(normalized_output_train))\n",
        "results_h5_train_flat = results_h5_train.flatten()\n",
        "print(np.shape(results_h5_train_flat))\n",
        "print(np.shape(normalized_output_train))\n",
        "r2 = r2_score(results_h5_train_flat,normalized_output_train)\n",
        "print(\"H5 R2 Score:\", r2)\n",
        "\n",
        "mean_abs_err = np.mean(np.abs(results_h5_train_flat - normalized_output_train))\n",
        "print(\"H5 Mean Absolute Error:\", mean_abs_err)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bp8LeQXluhs",
        "outputId": "8ade45d5-17ad-4312-df57-ee04646f64be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the model:\n",
            "Printing summary of the model:\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer_0_input_0 (InputLaye  [(None, 5)]               0         \n",
            " r)                                                              \n",
            "                                                                 \n",
            " layer_0_output_0 (Dense)    (None, 256)               1536      \n",
            "                                                                 \n",
            " layer_1_output_0 (Activati  (None, 256)               0         \n",
            " on)                                                             \n",
            "                                                                 \n",
            " layer_2_output_0 (Dense)    (None, 256)               65792     \n",
            "                                                                 \n",
            " layer_3_output_0 (Activati  (None, 256)               0         \n",
            " on)                                                             \n",
            "                                                                 \n",
            " layer_4_output_0 (Dense)    (None, 256)               65792     \n",
            "                                                                 \n",
            " layer_5_output_0 (Activati  (None, 256)               0         \n",
            " on)                                                             \n",
            "                                                                 \n",
            " layer_6_output_0 (Dense)    (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133377 (521.00 KB)\n",
            "Trainable params: 133377 (521.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "38/38 [==============================] - 0s 2ms/step\n",
            "(1202, 1) (1202,)\n",
            "(1202,)\n",
            "(1202,)\n",
            "H5 R2 Score: 0.9065386056900024\n",
            "H5 Mean Absolute Error: 0.19200696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LABEL REGRESSION OUTPUTS, 0 ( Y-YIDEAL > 0.192 (MAE)) ELSE 1)**"
      ],
      "metadata": {
        "id": "zhlHR5N-wnqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LABEL INPUTS 0 ( Y-YIDEAL > 1.0854 ELSE 1)\n",
        "labels_train = []\n",
        "op_vals_cor = []\n",
        "op_vals_inc = []\n",
        "for indx in range(0,len(normalized_data_train)):\n",
        "  if (np.abs(normalized_output_train[indx] - results_h5_train_flat[indx]) >= 0.19200696):\n",
        "    labels_train.append(0)\n",
        "    op_vals_inc.append(results_h5_train_flat[indx])\n",
        "  else:\n",
        "    labels_train.append(1)\n",
        "    op_vals_cor.append(results_h5_train_flat[indx])\n",
        "\n",
        "print(\"TR COUNT 1:\", labels_train.count(1))\n",
        "print(\"TR COUNT 0:\", labels_train.count(0))\n",
        "\n",
        "print(\"MEAN CORRECT OP VAL:\", np.mean(op_vals_cor))\n",
        "print(\"MAX CORRECT OP VAL:\", np.max(op_vals_cor))\n",
        "print(\"MIN CORRECT OP VAL:\", np.min(op_vals_cor))\n",
        "std_dev_cor = np.std(op_vals_cor)\n",
        "print(\"STD CORRECT OP VAL:\", std_dev_cor)\n",
        "\n",
        "print(\"MEAN INCORRECT OP VAL:\", np.mean(op_vals_inc))\n",
        "print(\"MAX INCORRECT OP VAL:\", np.max(op_vals_inc))\n",
        "print(\"MIN INCORRECT OP VAL:\", np.min(op_vals_inc))\n",
        "std_dev_inc = np.std(op_vals_inc)\n",
        "print(\"STD CORRECT OP VAL:\", std_dev_inc)\n",
        "\n",
        "\n",
        "\n",
        "results_h5_test = model_h5.predict(normalized_data_test)\n",
        "results_h5_test_flat = results_h5_test.flatten()\n",
        "\n",
        "\n",
        "labels_test = []\n",
        "for indx in range(0,len(normalized_data_test)):\n",
        "  if (np.abs(normalized_output_test[indx] - results_h5_test_flat[indx]) >= 0.19200696):\n",
        "    labels_test.append(0)\n",
        "  else:\n",
        "    labels_test.append(1)\n",
        "\n",
        "print(\"TEST COUNT 1:\", labels_test.count(1))\n",
        "print(\"TEST COUNT 0:\", labels_test.count(0))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeUzRN3hvJUa",
        "outputId": "560e4ed5-b606-43c9-f219-e402d985955a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TR COUNT 1: 788\n",
            "TR COUNT 0: 414\n",
            "MEAN CORRECT OP VAL: -0.08674386\n",
            "MAX CORRECT OP VAL: 1.9108756\n",
            "MIN CORRECT OP VAL: -3.1071632\n",
            "STD CORRECT OP VAL: 0.94361866\n",
            "MEAN INCORRECT OP VAL: 0.16865167\n",
            "MAX INCORRECT OP VAL: 1.9617213\n",
            "MIN INCORRECT OP VAL: -2.936437\n",
            "STD CORRECT OP VAL: 0.93601966\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "TEST COUNT 1: 171\n",
            "TEST COUNT 0: 130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('./x_train_npy.npy',normalized_data_train)\n",
        "np.save('./y_train_npy.npy',labels_train)\n",
        "np.save('./x_test_npy.npy',normalized_data_test)\n",
        "np.save('./y_test_npy.npy',labels_test)"
      ],
      "metadata": {
        "id": "DuVKtNFj0Y2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rules from layer 5 based on (on/off) activations**"
      ],
      "metadata": {
        "id": "v5PFQoSxzyJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m prophecy.main -m '/content/ProphecyPlus/dataset_models/airfoil_self_noise/model.h5' -wd '/content/ProphecyPlus/results/airfoil_self_noise/' analyze -tx ./x_train_npy.npy -ty ./y_train_npy.npy -vx ./x_test_npy.npy -vy ./y_test_npy.npy -layer 'layer_5_output_0' -type 3 -acts True"
      ],
      "metadata": {
        "id": "QLo6ufSnneFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3506e1-3cee-4aff-cec3-e3fde77d3c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "CONFIG PARAMS: LAYER NAME: layer_5_output_0 ,TYPE: 3 ,INP TYPE: 0 ,ACTS: True ,Top/All: False\n",
            "Layer Name: layer_5_output_0\n",
            "Layers to be considered for fingerprinting: ['layer_5_output_0']\n",
            "Invoking Dec-tree classifier based on FEATURES\n",
            "\n",
            "Fingerprinting TRAIN data after layer_5_output_0 layer\n",
            "Fingerprint after layer_5_output_0. ((1202, 256) inputs, (1202, 256) neurons)\n",
            "Inputs: (neuron signature (On/Off activations) dataset)(labels dataset)\n",
            "(1202, 256) (1202,)\n",
            "\n",
            "RULES FROM LAYER LAYER_5_OUTPUT_0 IN TERMS OF FEATURES\n",
            "\n",
            "Obtained all paths\n",
            "\rProcessing paths for training set:   0% 0/297 [00:00<?, ?it/s]\rProcessing paths for training set: 100% 297/297 [00:00<00:00, 1315425.86it/s]\n",
            "InV 0\n",
            "impure:\n",
            "[[155, 97, 39, 80, 129, 7, 130, 164, 209, 160, 196, 152, 123], [0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0], -1]\n",
            "\n",
            "Fingerprinting VAL data after layer_5_output_0 layer\n",
            "Fingerprint after layer_5_output_0. ((301, 256) inputs, (301, 256) neurons)\n",
            "PRINTING ALL RULES.\n",
            "impure:\n",
            "[[155, 97, 39, 80, 129, 7, 130, 164, 209, 160, 196, 152, 123], [0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0], -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "_output_path = \"/content/ProphecyPlus/results/airfoil_self_noise/ruleset.csv\"\n",
        "\n",
        "\n",
        "print(\"****** RULES ********\")\n",
        "df_op = pd.read_csv(_output_path)\n",
        "df_op = df_op[df_op['test_precision'] > 90.0]\n",
        "df_op = df_op[df_op['label'] == 1]\n",
        "\n",
        "\n",
        "df_op.to_csv(\"./rules_5_1.csv\",index=False)\n",
        "\n",
        "\n",
        "df_op = pd.read_csv(_output_path)\n",
        "df_op = df_op[df_op['test_precision'] > 90.0]\n",
        "df_op = df_op[df_op['label'] == 0]\n",
        "\n",
        "\n",
        "df_op.to_csv(\"./rules_5_0.csv\",index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9rH6uFx1LGX",
        "outputId": "415dfe1d-292b-417a-e016-ade5fc2d0f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****** RULES ********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rules from layer 4 based on neuron values**"
      ],
      "metadata": {
        "id": "qZmZtXYu15P5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m prophecy.main -m '/content/ProphecyPlus/dataset_models/airfoil_self_noise/model.h5' -wd '/content/ProphecyPlus/results/airfoil_self_noise/' analyze -tx ./x_train_npy.npy -ty ./y_train_npy.npy -vx ./x_test_npy.npy -vy ./y_test_npy.npy -layer 'layer_4_output_0' -type 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2y9a77v1yg-",
        "outputId": "9e9e4337-dbf1-4bd1-c461-f9fa81dc4f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "CONFIG PARAMS: LAYER NAME: layer_4_output_0 ,TYPE: 3 ,INP TYPE: 0 ,ACTS: False ,Top/All: False\n",
            "Layer Name: layer_4_output_0\n",
            "Layers to be considered for fingerprinting: ['layer_4_output_0']\n",
            "Invoking Dec-tree classifier based on FEATURES\n",
            "\n",
            "Fingerprinting TRAIN data after layer_4_output_0 layer\n",
            "Fingerprint after layer_4_output_0. ((1202, 256) inputs, (1202, 256) neurons)\n",
            "Inputs: (neuron signature (On/Off activations) dataset)(labels dataset)\n",
            "(1202, 256) (1202,)\n",
            "\n",
            "RULES FROM LAYER LAYER_4_OUTPUT_0 IN TERMS OF FEATURES\n",
            "\n",
            "Obtained all paths\n",
            "Processing paths for validation set: 100% 139/139 [00:00<00:00, 1067780.69it/s]\n",
            "InV 0\n",
            "\n",
            "Fingerprinting VAL data after layer_4_output_0 layer\n",
            "Fingerprint after layer_4_output_0. ((301, 256) inputs, (301, 256) neurons)\n",
            "PRINTING ALL RULES.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "_output_path = \"/content/ProphecyPlus/results/airfoil_self_noise/ruleset.csv\"\n",
        "\n",
        "\n",
        "print(\"****** RULES ********\")\n",
        "df_op = pd.read_csv(_output_path)\n",
        "df_op = df_op[df_op['test_precision'] > 90.0]\n",
        "df_op = df_op[df_op['label'] == 1]\n",
        "df_op.to_csv(\"./rules_4_1.csv\",index=False)\n",
        "\n",
        "\n",
        "df_op = pd.read_csv(_output_path)\n",
        "df_op = df_op[df_op['test_precision'] > 90.0]\n",
        "df_op = df_op[df_op['label'] == 0]\n",
        "df_op.to_csv(\"./rules_4_0.csv\",index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjnx8YwH2UJC",
        "outputId": "692c6fd2-8715-4199-adb6-84818c064100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****** RULES ********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m prophecy.main -m '/content/ProphecyPlus/dataset_models/airfoil_self_noise/model.h5' -wd '/content/ProphecyPlus/results/airfoil_self_noise/' analyze -tx ./x_train_npy.npy -ty ./y_train_npy.npy -vx ./x_test_npy.npy -vy ./y_test_npy.npy -layer 'layer_3_output_0' -type 3 -acts True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pANE0ebP2sRZ",
        "outputId": "9520dfe9-9c9c-40cf-bc04-1a22d943118e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "CONFIG PARAMS: LAYER NAME: layer_3_output_0 ,TYPE: 3 ,INP TYPE: 0 ,ACTS: True ,Top/All: False\n",
            "Layer Name: layer_3_output_0\n",
            "Layers to be considered for fingerprinting: ['layer_3_output_0']\n",
            "Invoking Dec-tree classifier based on FEATURES\n",
            "\n",
            "Fingerprinting TRAIN data after layer_3_output_0 layer\n",
            "Fingerprint after layer_3_output_0. ((1202, 256) inputs, (1202, 256) neurons)\n",
            "Inputs: (neuron signature (On/Off activations) dataset)(labels dataset)\n",
            "(1202, 256) (1202,)\n",
            "\n",
            "RULES FROM LAYER LAYER_3_OUTPUT_0 IN TERMS OF FEATURES\n",
            "\n",
            "Obtained all paths\n",
            "\rProcessing paths for training set:   0% 0/276 [00:00<?, ?it/s]\rProcessing paths for training set: 100% 276/276 [00:00<00:00, 1408306.45it/s]\n",
            "InV 0\n",
            "impure:\n",
            "[[24, 132, 31, 217, 91, 189, 104, 94], [0, 1, 0, 1, 1, 0, 0, 1], -1]\n",
            "\n",
            "Fingerprinting VAL data after layer_3_output_0 layer\n",
            "Fingerprint after layer_3_output_0. ((301, 256) inputs, (301, 256) neurons)\n",
            "PRINTING ALL RULES.\n",
            "impure:\n",
            "[[24, 132, 31, 217, 91, 189, 104, 94], [0, 1, 0, 1, 1, 0, 0, 1], -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "_output_path = \"/content/ProphecyPlus/results/airfoil_self_noise/ruleset.csv\"\n",
        "\n",
        "\n",
        "print(\"****** RULES ********\")\n",
        "df_op = pd.read_csv(_output_path)\n",
        "df_op = df_op[df_op['test_precision'] > 90.0]\n",
        "df_op = df_op[df_op['label'] == 1]\n",
        "\n",
        "\n",
        "df_op.to_csv(\"./rules_3_1.csv\",index=False)\n",
        "\n",
        "\n",
        "df_op = pd.read_csv(_output_path)\n",
        "df_op = df_op[df_op['test_precision'] > 90.0]\n",
        "df_op = df_op[df_op['label'] == 0]\n",
        "\n",
        "\n",
        "df_op.to_csv(\"./rules_3_0.csv\",index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d493fe8d-b731-42bb-8e24-e7068c673ab9",
        "id": "Z_B3Yaln2scn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****** RULES ********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m prophecy.main -m '/content/ProphecyPlus/dataset_models/airfoil_self_noise/model.h5' -wd '/content/ProphecyPlus/results/airfoil_self_noise/' analyze -tx ./x_train_npy.npy -ty ./y_train_npy.npy -vx ./x_test_npy.npy -vy ./y_test_npy.npy -layer 'layer_2_output_0' -type 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwN9MViL230H",
        "outputId": "048875be-3150-4682-ed36-fc7c59551d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "CONFIG PARAMS: LAYER NAME: layer_2_output_0 ,TYPE: 3 ,INP TYPE: 0 ,ACTS: False ,Top/All: False\n",
            "Layer Name: layer_2_output_0\n",
            "Layers to be considered for fingerprinting: ['layer_2_output_0']\n",
            "Invoking Dec-tree classifier based on FEATURES\n",
            "\n",
            "Fingerprinting TRAIN data after layer_2_output_0 layer\n",
            "Fingerprint after layer_2_output_0. ((1202, 256) inputs, (1202, 256) neurons)\n",
            "Inputs: (neuron signature (On/Off activations) dataset)(labels dataset)\n",
            "(1202, 256) (1202,)\n",
            "\n",
            "RULES FROM LAYER LAYER_2_OUTPUT_0 IN TERMS OF FEATURES\n",
            "\n",
            "Obtained all paths\n",
            "Processing paths for validation set: 100% 142/142 [00:00<00:00, 1167825.82it/s]\n",
            "InV 0\n",
            "\n",
            "Fingerprinting VAL data after layer_2_output_0 layer\n",
            "Fingerprint after layer_2_output_0. ((301, 256) inputs, (301, 256) neurons)\n",
            "PRINTING ALL RULES.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "_output_path = \"/content/ProphecyPlus/results/airfoil_self_noise/ruleset.csv\"\n",
        "\n",
        "\n",
        "print(\"****** RULES ********\")\n",
        "df_op = pd.read_csv(_output_path)\n",
        "df_op = df_op[df_op['test_precision'] > 90.0]\n",
        "df_op = df_op[df_op['label'] == 1]\n",
        "\n",
        "\n",
        "df_op.to_csv(\"./rules_2_1.csv\",index=False)\n",
        "\n",
        "\n",
        "df_op = pd.read_csv(_output_path)\n",
        "df_op = df_op[df_op['test_precision'] > 90.0]\n",
        "df_op = df_op[df_op['label'] == 0]\n",
        "\n",
        "\n",
        "df_op.to_csv(\"./rules_2_0.csv\",index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NRSgD0d2_kv",
        "outputId": "c956b411-9704-44d7-8dd3-fc78d4d2823e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****** RULES ********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m prophecy.main -m '/content/ProphecyPlus/dataset_models/airfoil_self_noise/model.h5' -wd '/content/ProphecyPlus/results/airfoil_self_noise/' analyze -tx ./x_train_npy.npy -ty ./y_train_npy.npy -vx ./x_test_npy.npy -vy ./y_test_npy.npy -layer 'layer_1_output_0' -type 3 -acts True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJNb4Jww3JGN",
        "outputId": "599a2e29-7b3e-4fa8-ae0d-f8958fb224ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "CONFIG PARAMS: LAYER NAME: layer_1_output_0 ,TYPE: 3 ,INP TYPE: 0 ,ACTS: True ,Top/All: False\n",
            "Layer Name: layer_1_output_0\n",
            "Layers to be considered for fingerprinting: ['layer_1_output_0']\n",
            "Invoking Dec-tree classifier based on FEATURES\n",
            "\n",
            "Fingerprinting TRAIN data after layer_1_output_0 layer\n",
            "Fingerprint after layer_1_output_0. ((1202, 256) inputs, (1202, 256) neurons)\n",
            "Inputs: (neuron signature (On/Off activations) dataset)(labels dataset)\n",
            "(1202, 256) (1202,)\n",
            "\n",
            "RULES FROM LAYER LAYER_1_OUTPUT_0 IN TERMS OF FEATURES\n",
            "\n",
            "Obtained all paths\n",
            "\rProcessing paths for training set:   0% 0/287 [00:00<?, ?it/s]\rProcessing paths for training set: 100% 287/287 [00:00<00:00, 1523753.48it/s]\n",
            "InV 0\n",
            "impure:\n",
            "[[152, 215, 19, 122, 170, 40, 213, 173, 219, 144, 114, 140, 222, 247, 253, 137], [0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1], -1]\n",
            "\n",
            "Fingerprinting VAL data after layer_1_output_0 layer\n",
            "Fingerprint after layer_1_output_0. ((301, 256) inputs, (301, 256) neurons)\n",
            "PRINTING ALL RULES.\n",
            "impure:\n",
            "[[152, 215, 19, 122, 170, 40, 213, 173, 219, 144, 114, 140, 222, 247, 253, 137], [0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1], -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "_output_path = \"/content/ProphecyPlus/results/airfoil_self_noise/ruleset.csv\"\n",
        "\n",
        "\n",
        "print(\"****** RULES ********\")\n",
        "df_op = pd.read_csv(_output_path)\n",
        "df_op = df_op[df_op['test_precision'] > 90.0]\n",
        "df_op = df_op[df_op['label'] == 1]\n",
        "\n",
        "\n",
        "df_op.to_csv(\"./rules_1_1.csv\",index=False)\n",
        "\n",
        "\n",
        "df_op = pd.read_csv(_output_path)\n",
        "df_op = df_op[df_op['test_precision'] > 90.0]\n",
        "df_op = df_op[df_op['label'] == 0]\n",
        "\n",
        "\n",
        "df_op.to_csv(\"./rules_1_0.csv\",index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5FPze6R3Tdi",
        "outputId": "2c70bdd4-f1fc-47fe-83ee-af452ac3928c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****** RULES ********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m prophecy.main -m '/content/ProphecyPlus/dataset_models/airfoil_self_noise/model.h5' -wd '/content/ProphecyPlus/results/airfoil_self_noise/' analyze -tx ./x_train_npy.npy -ty ./y_train_npy.npy -vx ./x_test_npy.npy -vy ./y_test_npy.npy -layer 'layer_0_output_0' -type 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tThgs7s13Jye",
        "outputId": "214d2c7f-6527-4028-83e3-5ec5b0bcd6aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "CONFIG PARAMS: LAYER NAME: layer_0_output_0 ,TYPE: 3 ,INP TYPE: 0 ,ACTS: False ,Top/All: False\n",
            "Layer Name: layer_0_output_0\n",
            "Layers to be considered for fingerprinting: ['layer_0_output_0']\n",
            "Invoking Dec-tree classifier based on FEATURES\n",
            "\n",
            "Fingerprinting TRAIN data after layer_0_output_0 layer\n",
            "Fingerprint after layer_0_output_0. ((1202, 256) inputs, (1202, 256) neurons)\n",
            "Inputs: (neuron signature (On/Off activations) dataset)(labels dataset)\n",
            "(1202, 256) (1202,)\n",
            "\n",
            "RULES FROM LAYER LAYER_0_OUTPUT_0 IN TERMS OF FEATURES\n",
            "\n",
            "Obtained all paths\n",
            "Processing paths for validation set: 100% 164/164 [00:00<00:00, 1230529.26it/s]\n",
            "InV 0\n",
            "\n",
            "Fingerprinting VAL data after layer_0_output_0 layer\n",
            "Fingerprint after layer_0_output_0. ((301, 256) inputs, (301, 256) neurons)\n",
            "PRINTING ALL RULES.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "_output_path = \"/content/ProphecyPlus/results/airfoil_self_noise/ruleset.csv\"\n",
        "\n",
        "\n",
        "print(\"****** RULES ********\")\n",
        "df_op = pd.read_csv(_output_path)\n",
        "df_op = df_op[df_op['test_precision'] > 90.0]\n",
        "df_op = df_op[df_op['train_recall'] > 50.0]\n",
        "df_op = df_op[df_op['label'] == 1]\n",
        "\n",
        "df_op.to_csv(\"./rules_0_1.csv\",index=False)\n",
        "\n",
        "\n",
        "df_op = pd.read_csv(_output_path)\n",
        "df_op = df_op[df_op['test_precision'] > 90.0]\n",
        "df_op = df_op[df_op['label'] == 0]\n",
        "\n",
        "\n",
        "df_op.to_csv(\"./rules_0_0.csv\",index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI3qNJzb3XDr",
        "outputId": "6a1e9d3f-f4af-478c-9d9b-8e93ded44f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****** RULES ********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_op = pd.read_csv(\"./rules_0_0.csv\")\n",
        "df_op = df_op[df_op.index == 0]\n",
        "train_f1 = (df_op['train_f1']).values[0]\n",
        "test_f1 = (df_op['test_f1']).values[0]\n",
        "\n",
        "print(\"RULE 0 0:\", train_f1,\",\",test_f1)\n",
        "\n",
        "\n",
        "\n",
        "df_op = pd.read_csv(\"./rules_0_1.csv\")\n",
        "df_op = df_op[df_op.index == 0]\n",
        "train_f1 = (df_op['train_f1']).values[0]\n",
        "test_f1 = (df_op['test_f1']).values[0]\n",
        "\n",
        "print(\"RULE 0 1:\", train_f1,\",\",test_f1)\n",
        "\n",
        "df_op = pd.read_csv(\"./rules_1_0.csv\")\n",
        "df_op = df_op[df_op.index == 0]\n",
        "train_f1 = (df_op['train_f1']).values[0]\n",
        "test_f1 = (df_op['test_f1']).values[0]\n",
        "\n",
        "print(\"RULE 1 0:\", train_f1,\",\",test_f1)\n",
        "\n",
        "\n",
        "\n",
        "df_op = pd.read_csv(\"./rules_1_1.csv\")\n",
        "df_op = df_op[df_op.index == 0]\n",
        "train_f1 = (df_op['train_f1']).values[0]\n",
        "test_f1 = (df_op['test_f1']).values[0]\n",
        "\n",
        "print(\"RULE 1 1:\", train_f1,\",\",test_f1)\n",
        "\n",
        "df_op = pd.read_csv(\"./rules_2_0.csv\")\n",
        "df_op = df_op[df_op.index == 0]\n",
        "train_f1 = (df_op['train_f1']).values[0]\n",
        "test_f1 = (df_op['test_f1']).values[0]\n",
        "\n",
        "print(\"RULE 2 0:\", train_f1,\",\",test_f1)\n",
        "\n",
        "\n",
        "\n",
        "df_op = pd.read_csv(\"./rules_2_1.csv\")\n",
        "df_op = df_op[df_op.index == 0]\n",
        "train_f1 = (df_op['train_f1']).values[0]\n",
        "test_f1 = (df_op['test_f1']).values[0]\n",
        "\n",
        "print(\"RULE 2 1:\", train_f1,\",\",test_f1)\n",
        "\n",
        "df_op = pd.read_csv(\"./rules_3_0.csv\")\n",
        "df_op = df_op[df_op.index == 0]\n",
        "train_f1 = (df_op['train_f1']).values[0]\n",
        "test_f1 = (df_op['test_f1']).values[0]\n",
        "\n",
        "print(\"RULE 3 0:\", train_f1,\",\",test_f1)\n",
        "\n",
        "\n",
        "\n",
        "df_op = pd.read_csv(\"./rules_3_1.csv\")\n",
        "df_op = df_op[df_op.index == 0]\n",
        "train_f1 = (df_op['train_f1']).values[0]\n",
        "test_f1 = (df_op['test_f1']).values[0]\n",
        "\n",
        "print(\"RULE 3 1:\", train_f1,\",\",test_f1)\n",
        "\n",
        "df_op = pd.read_csv(\"./rules_4_0.csv\")\n",
        "df_op = df_op[df_op.index == 0]\n",
        "train_f1 = (df_op['train_f1']).values[0]\n",
        "test_f1 = (df_op['test_f1']).values[0]\n",
        "\n",
        "print(\"RULE 4 0:\", train_f1,\",\",test_f1)\n",
        "\n",
        "\n",
        "\n",
        "df_op = pd.read_csv(\"./rules_4_1.csv\")\n",
        "df_op = df_op[df_op.index == 0]\n",
        "train_f1 = (df_op['train_f1']).values[0]\n",
        "test_f1 = (df_op['test_f1']).values[0]\n",
        "\n",
        "print(\"RULE 4 1:\", train_f1,\",\",test_f1)\n",
        "\n",
        "df_op = pd.read_csv(\"./rules_5_0.csv\")\n",
        "df_op = df_op[df_op.index == 0]\n",
        "train_f1 = (df_op['train_f1']).values[0]\n",
        "test_f1 = (df_op['test_f1']).values[0]\n",
        "\n",
        "print(\"RULE 5 0:\", train_f1,\",\",test_f1)\n",
        "\n",
        "\n",
        "\n",
        "df_op = pd.read_csv(\"./rules_5_1.csv\")\n",
        "df_op = df_op[df_op.index == 0]\n",
        "train_f1 = (df_op['train_f1']).values[0]\n",
        "test_f1 = (df_op['test_f1']).values[0]\n",
        "\n",
        "print(\"RULE 5 1:\", train_f1,\",\",test_f1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bsUM5Nt3e5s",
        "outputId": "880b167c-b6df-455d-c8ec-c091b9862a58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RULE 0 0: 9.655172413793103 , 15.602836879432624\n",
            "RULE 0 1: 5.19159456118665 , 1.162790697674419\n",
            "RULE 1 0: 7.88863109048724 , 8.823529411764707\n",
            "RULE 1 1: 3.0000000000000004 , 2.312138728323699\n",
            "RULE 2 0: 3.32541567695962 , 1.5267175572519085\n",
            "RULE 2 1: 8.038976857490866 , 10.0\n",
            "RULE 3 0: 1.9138755980861248 , 1.5267175572519085\n",
            "RULE 3 1: 4.708798017348204 , 3.4482758620689653\n",
            "RULE 4 0: 0.4819277108433735 , 1.5267175572519085\n",
            "RULE 4 1: 4.950495049504951 , 1.162790697674419\n",
            "RULE 5 0: 1.4388489208633093 , 1.5267175572519085\n",
            "RULE 5 1: 14.806110458284373 , 1.162790697674419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_op = pd.read_csv(\"./rules_5_0.csv\")\n",
        "df_op = df_op[df_op.index == 0]\n",
        "rule_5_0_neurons = df_op['neurons']\n",
        "rule_5_0_signature = df_op['signature']\n",
        "\n",
        "\n",
        "df_op = pd.read_csv(\"./rules_5_1.csv\")\n",
        "df_op = df_op[df_op.index == 0]\n",
        "rule_5_1_neurons = df_op['neurons']\n",
        "rule_5_1_signature = df_op['signature']\n",
        "\n",
        "df_op = pd.read_csv(\"./rules_4_0.csv\")\n",
        "df_op = df_op[df_op.index == 0]\n",
        "rule_4_0_neurons = df_op['neurons']\n",
        "rule_4_0_signature = df_op['signature']\n",
        "\n",
        "\n",
        "df_op = pd.read_csv(\"./rules_4_1.csv\")\n",
        "df_op = df_op[df_op.index == 0]\n",
        "rule_4_1_neurons = df_op['neurons']\n",
        "rule_4_1_signature = df_op['signature']\n",
        "\n",
        "\n",
        "print(rule_4_0_neurons.array[0])\n",
        "print(rule_4_0_signature.array[0])\n",
        "print(rule_4_1_neurons.array[0])\n",
        "print(rule_4_1_signature.array[0])\n",
        "\n",
        "\n",
        "print(rule_5_0_neurons.array[0])\n",
        "print(rule_5_0_signature.array[0])\n",
        "print(rule_5_1_neurons.array[0])\n",
        "print(rule_5_1_signature.array[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaMIfj-X4pJL",
        "outputId": "b581ab47-7a82-4805-b236-8aad19035b20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[29, 215, 181, 86, 192, 0, 70, 147, 91, 26, 250, 195]\n",
            "['<=', 0.2756440043449402, '>', -0.5447605848312378, '>', -0.05165771581232548, '<=', 0.371839240193367, '<=', 0.3212895691394806, '>', -0.12406855449080467, '>', -0.15119200199842453, '<=', 0.07985635101795197, '>', 0.07166659459471703, '<=', 0.22430628538131714, '>', 0.11450915783643723, '>', 0.19882015138864517]\n",
            "[29, 215, 181, 86, 192, 0, 70, 147, 144, 76, 193]\n",
            "['<=', 0.2756440043449402, '>', -0.5447605848312378, '>', -0.05165771581232548, '<=', 0.371839240193367, '<=', 0.3212895691394806, '>', -0.12406855449080467, '>', -0.15119200199842453, '>', 0.07985635101795197, '>', 0.14457079768180847, '>', 0.44639018177986145, '<=', 0.4770570695400238]\n",
            "[155, 191, 181, 138, 157, 103, 192, 204, 134, 169, 32]\n",
            "[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0]\n",
            "[155, 97, 39, 219, 23, 11]\n",
            "[0, 0, 0, 0, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_pattern(layer_vals: list, neuron_ids: list, neuron_sig: list) -> bool:\n",
        "    \"\"\"\n",
        "        Check if the provided layer values satisfy the provided neuron signature.\n",
        "    :param layer_vals:\n",
        "    :param neuron_ids:\n",
        "    :param neuron_sig:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    found = True\n",
        "    oper = -1\n",
        "    # layer_vals = (layer_vals).flatten()\n",
        "\n",
        "    for ind in range(0, len(neuron_sig)):\n",
        "        if ind % 2 == 0:\n",
        "            op = neuron_sig[ind]\n",
        "            if op == '<=':\n",
        "                oper = 0\n",
        "            else:\n",
        "                oper = 1\n",
        "        else:\n",
        "            v = int(neuron_ids[(int)(ind / 2)])\n",
        "            vsig = float(neuron_sig[ind])\n",
        "            val = float(layer_vals[v])\n",
        "            # print(v,vsig,val,oper)\n",
        "            if oper == 0:\n",
        "                if val > vsig:\n",
        "                    # print(v,val,vsig,oper)\n",
        "                    found = False\n",
        "                    break\n",
        "            else:\n",
        "                if val <= vsig:\n",
        "                    # print(v,val,vsig,oper)\n",
        "                    found = False\n",
        "                    break\n",
        "            oper = -1\n",
        "\n",
        "    return found\n",
        "\n",
        "def get_suffix_cluster(neuron_ids, neuron_sig, suffixes, VAL=False):\n",
        "    # Get the cluster of inputs that such that all inputs in the cluster\n",
        "    # have provided on/off signature for the provided neurons.\n",
        "    #\n",
        "    # The returned cluster is an array of indices (into mnist.train.images).\n",
        "    if (VAL == False):\n",
        "        return np.where((suffixes[:, neuron_ids] == neuron_sig).all(axis=1))[0]\n",
        "\n",
        "    matched_ids = []\n",
        "    # print(len(suffixes))\n",
        "    for indx in range(0, len(suffixes)):\n",
        "        if (check_pattern(suffixes[indx], neuron_ids, neuron_sig) == True):\n",
        "            matched_ids.append(indx)\n",
        "    # print(matched_ids)\n",
        "    return matched_ids\n",
        "\n"
      ],
      "metadata": {
        "id": "DhOuQnl_5StD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "model =tf.keras.models.load_model('/content/ProphecyPlus/dataset_models/airfoil_self_noise/model.h5')\n",
        "x_train = np.load('./x_train_npy.npy')\n",
        "y_train = np.load('./y_train_npy.npy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkc2eeSg5jn6",
        "outputId": "469c4b4a-1eeb-45d8-a551-daed1bc17047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend\n",
        "\n",
        "func5 = None\n",
        "func4 = None\n",
        "\n",
        "for layer in model.layers:\n",
        "    print(layer.name)\n",
        "    if (layer.name == 'layer_5_output_0'):\n",
        "      func5 = backend.function(model.input, [layer.output])\n",
        "    if (layer.name == 'layer_4_output_0'):\n",
        "      func4 = backend.function(model.input, [layer.output])\n",
        "\n",
        "\n",
        "fingerprint_5 = []\n",
        "fingerprint_4 = []\n",
        "\n",
        "if (func5 != None):\n",
        "  fingerprint_5 = func5(x_train)\n",
        "\n",
        "if (func4 != None):\n",
        "  fingerprint_4 = func4(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgCcXk2v5WuL",
        "outputId": "eb430b1a-edd6-4b9b-fb30-d8d66e8b902c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer_0_input_0\n",
            "layer_0_output_0\n",
            "layer_1_output_0\n",
            "layer_2_output_0\n",
            "layer_3_output_0\n",
            "layer_4_output_0\n",
            "layer_5_output_0\n",
            "layer_6_output_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(len(x_train))\n",
        "#x_train_flat = []\n",
        "#for indx in range(0, len(x_train)):\n",
        "#  x_train_flat.append((x_train[indx]).flatten())\n",
        "\n",
        "#x_train_flat = np.array(x_train_flat)\n",
        "print(np.shape(x_train))\n",
        "#print(np.shape(x_train_flat))\n",
        "\n",
        "print(np.shape(fingerprint_4[0]))\n",
        "print(np.shape(fingerprint_5[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDlh-6X66bJd",
        "outputId": "cf6e5a7d-7335-441b-8355-adc7deafeac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1202, 5)\n",
            "(1202, 256)\n",
            "(1202, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length = len(x_train[0])\n",
        "\n",
        "\n",
        "x_train_min = np.zeros(length)\n",
        "x_train_max = np.zeros(length)\n",
        "\n",
        "for indx in range(0,length):\n",
        "  x_train_min[indx] = np.min(x_train[:,indx])\n",
        "  x_train_max[indx] = np.max(x_train[:,indx])\n",
        "\n",
        "print(x_train_min)\n",
        "print(x_train_max)\n",
        "\n",
        "\n",
        "\n",
        "###########\n",
        "rule_neurons_list_4_1 = []\n",
        "rule_neurons = (rule_4_1_neurons.array[0]).split(\",\")\n",
        "for indx in range(0, len(rule_neurons)):\n",
        "    rule_neurons[indx] = (rule_neurons[indx]).strip()\n",
        "    rule_neurons[indx] = (rule_neurons[indx]).replace(\"[\", \"\")\n",
        "    rule_neurons[indx] = (rule_neurons[indx]).replace(\"]\",\"\")\n",
        "    rule_neurons_list_4_1.append(int(rule_neurons[indx]))\n",
        "\n",
        "print(rule_neurons_list_4_1)\n",
        "\n",
        "rule_sig_list_4_1 = []\n",
        "rule_sig = (rule_4_1_signature.array[0]).split(\",\")\n",
        "for indx in range(0, len(rule_sig)):\n",
        "    rule_sig[indx] = (rule_sig[indx]).strip()\n",
        "    rule_sig[indx] = (rule_sig[indx]).replace(\"[\", \"\")\n",
        "    rule_sig[indx] = (rule_sig[indx]).replace(\"]\",\"\")\n",
        "    if (indx % 2 == 0):\n",
        "      rule_sig[indx] = (rule_sig[indx]).replace(\"'\", \"\")\n",
        "      rule_sig_list_4_1.append(rule_sig[indx])\n",
        "    else:\n",
        "      rule_sig_list_4_1.append(float(rule_sig[indx]))\n",
        "\n",
        "print(rule_sig_list_4_1)\n",
        "\n",
        "fngprnt = fingerprint_4[0]\n",
        "indices = get_suffix_cluster(rule_neurons_list_4_1, rule_sig_list_4_1, fngprnt,VAL=True)\n",
        "print(\"indices:\", len(indices))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x_train_4_1 = []\n",
        "fngprnt_4_1 = []\n",
        "inp_ex_4_1 = []\n",
        "finger_ex_4_1 = []\n",
        "for indx in range(0, len(indices)):\n",
        "    if (indx == 0):\n",
        "      inp_ex_4_1 = x_train[indices[indx]]\n",
        "      finger_ex_4_1 = fingerprint_4[0][indices[indx]]\n",
        "\n",
        "    x_train_4_1.append(x_train[indices[indx]])\n",
        "    fngprnt_4_1.append(fingerprint_4[0][indices[indx]])\n",
        "\n",
        "x_train_4_1= np.array(x_train_4_1)\n",
        "fngprnt_4_1 = np.array(fngprnt_4_1)\n",
        "\n",
        "print(np.shape(x_train_4_1))\n",
        "x_train_min_4_1 = np.zeros(length)\n",
        "x_train_max_4_1 = np.zeros(length)\n",
        "\n",
        "for indx in range(0,length):\n",
        "  x_train_min_4_1[indx] = np.min(x_train_4_1[:,indx])\n",
        "  x_train_max_4_1[indx] = np.max(x_train_4_1[:,indx])\n",
        "\n",
        "print(x_train_min_4_1)\n",
        "print(x_train_max_4_1)\n",
        "\n",
        "print(np.shape(fngprnt_4_1))\n",
        "fngprnt_min_4_1 = np.zeros(len(fngprnt_4_1[0]))\n",
        "fngprnt_max_4_1 = np.zeros(len(fngprnt_4_1[0]))\n",
        "\n",
        "for indx in range(0,len(fngprnt_4_1[0])):\n",
        "  fngprnt_min_4_1[indx] = np.min(fngprnt_4_1[:,indx])\n",
        "  fngprnt_max_4_1[indx] = np.max(fngprnt_4_1[:,indx])\n",
        "\n",
        "print(fngprnt_min_4_1)\n",
        "print(fngprnt_max_4_1)\n",
        "\n",
        "\n",
        "print(\"INP:\", inp_ex_4_1)\n",
        "print(\"FINGER:\", finger_ex_4_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXEnmIqc6kFv",
        "outputId": "9b325cae-149d-4e46-9fc8-18d93fc5684f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.85240561 -1.1463989  -1.188622   -1.23082471 -0.81692582]\n",
            "[5.4302597  2.1834619  1.79929733 1.31291699 3.59591293]\n",
            "[29, 215, 181, 86, 192, 0, 70, 147, 144, 76, 193]\n",
            "['<=', 0.2756440043449402, '>', -0.5447605848312378, '>', -0.05165771581232548, '<=', 0.371839240193367, '<=', 0.3212895691394806, '>', -0.12406855449080467, '>', -0.15119200199842453, '>', 0.07985635101795197, '>', 0.14457079768180847, '>', 0.44639018177986145, '<=', 0.4770570695400238]\n",
            "indices: 20\n",
            "(20, 5)\n",
            "[-0.81591541 -1.1463989  -0.91699296 -1.23082471 -0.78562462]\n",
            "[-0.2812542  -0.63931352  1.79929733 -0.72336125 -0.44460684]\n",
            "(20, 256)\n",
            "[ 1.58695996e-01  3.07415068e-01  6.77956492e-02 -3.45776826e-01\n",
            " -9.15562287e-02 -5.88296428e-02 -4.90033388e-01  7.03734532e-02\n",
            "  3.58857304e-01  2.16475919e-01 -4.39988256e-01  3.02702397e-01\n",
            "  7.96297640e-02  5.53577691e-02  1.70178771e-01 -8.19604024e-02\n",
            "  2.85947267e-02  2.60811925e-01 -5.93821764e-01  5.02605885e-02\n",
            " -2.65997928e-03  7.55193532e-02  8.19150358e-03  3.51664126e-01\n",
            "  8.19967836e-02  8.06677341e-02  8.95511284e-02 -7.62404129e-02\n",
            "  2.44173221e-02  6.74847439e-02 -1.41250268e-02 -9.63127911e-02\n",
            " -1.20408669e-01  3.24465632e-02 -1.36462584e-01  1.33877859e-01\n",
            "  1.57112747e-01  9.53489542e-02  2.82379687e-01 -2.08826080e-01\n",
            " -3.07228625e-01 -7.12131739e-01  5.35333902e-02  1.72973573e-01\n",
            "  3.85213643e-01 -6.81997016e-02 -1.59113288e-01  3.75437468e-01\n",
            "  6.25269413e-02 -1.25515610e-02  1.30184650e-01 -2.98602059e-02\n",
            " -3.47487032e-02 -9.49111432e-02 -3.34720761e-01 -2.09120184e-01\n",
            "  2.92915016e-01  2.94250175e-02  1.05822355e-01 -4.75851208e-01\n",
            "  8.13916326e-02 -9.43290256e-03 -4.95191775e-02  1.06714979e-01\n",
            "  3.08330089e-01 -2.57961191e-02  1.92357808e-01  1.72199130e-01\n",
            "  5.93883321e-02 -3.01829129e-02 -1.50534347e-01 -3.41525882e-01\n",
            " -2.23609492e-01  2.34792799e-01 -4.05050099e-01  3.65693390e-01\n",
            "  4.48689550e-01  4.33303744e-01  9.59381908e-02  3.15681934e-01\n",
            " -1.17408514e-01 -3.48432660e-01  2.25956112e-01 -6.40426576e-02\n",
            " -1.95157900e-02  2.59223953e-03  1.51704922e-02 -5.57597816e-01\n",
            " -7.30109811e-01  2.44574428e-01 -1.57299027e-01  1.33488506e-01\n",
            "  4.80277315e-02  2.23312564e-02  6.87469691e-02  1.77958861e-01\n",
            "  3.04885000e-01 -4.46394324e-01 -1.72924269e-02  8.68512541e-02\n",
            "  1.53542593e-01  8.39726627e-03  1.04234651e-01 -1.08564392e-01\n",
            "  2.08930343e-01 -1.46524072e-01  1.49403915e-01  5.34568913e-02\n",
            " -3.59701067e-01 -3.18000913e-01  6.23928234e-02  6.74622878e-02\n",
            "  3.03530306e-01 -2.57896960e-01  1.78303137e-01  2.99007893e-01\n",
            " -1.69221088e-02  1.01020344e-01  1.52487643e-02  5.64239882e-02\n",
            "  7.45701045e-02  3.82006355e-02  1.14166245e-01 -2.68208206e-01\n",
            "  2.10343689e-01  3.16045463e-01  1.59784615e-01  9.86452587e-03\n",
            " -4.55644950e-02  1.19740918e-01 -7.19192803e-01  1.22596480e-01\n",
            "  2.54377514e-01  1.08008064e-01 -6.65345415e-03 -5.46500785e-03\n",
            " -3.76675427e-02  2.44105294e-01  4.50443178e-02  2.10092738e-01\n",
            " -4.55614567e-01  1.03012305e-02  2.43000686e-02  3.40030074e-01\n",
            "  1.45673320e-01  3.55573632e-02  1.98065862e-01  8.09001252e-02\n",
            " -3.19247283e-02 -1.07701743e+00  1.12725578e-01  2.20983326e-01\n",
            " -1.22983381e-02  3.65939327e-02 -7.42300004e-02  4.66909781e-02\n",
            " -8.76425087e-01 -1.81583866e-01 -4.22300622e-02 -4.37316671e-02\n",
            " -3.18092763e-01  1.75788075e-01 -1.35267544e+00 -6.24093078e-02\n",
            " -5.23084223e-01  3.17262679e-01 -5.49037382e-02  1.51078343e-01\n",
            " -3.00183862e-01 -5.84367365e-02  2.08881199e-01 -6.37547255e-01\n",
            "  2.98356682e-01  1.00470223e-01  9.81359631e-02 -2.33076259e-01\n",
            "  1.15242228e-01 -3.00464302e-01 -1.07951388e-02 -9.41754878e-03\n",
            "  4.03209478e-01 -5.16360551e-02  4.66560572e-03 -3.17596287e-01\n",
            " -3.67609337e-02 -5.56188941e-01  6.60827011e-02  4.17450853e-02\n",
            "  2.06974179e-01 -4.19840477e-02  2.62492269e-01  7.79838189e-02\n",
            " -2.05903113e-01  1.99310966e-02  1.26572669e-01  1.35204002e-01\n",
            "  4.44388390e-02 -4.09076542e-01  2.35243648e-01  2.24678740e-02\n",
            "  2.74394333e-01  2.98605748e-02 -5.04756942e-02  2.44888157e-01\n",
            " -1.23263419e-01  2.48528749e-01 -7.55287826e-01  4.68246222e-01\n",
            " -4.06721562e-01  2.71342218e-01 -8.88066180e-03  2.19462842e-01\n",
            "  1.19986713e-01  1.15012527e-01  5.98508194e-02 -5.34474850e-01\n",
            "  1.09678470e-01  1.97292164e-01  1.41481921e-01  9.80482437e-04\n",
            " -4.86706123e-02  3.75131518e-02 -3.88440937e-02 -2.83615708e-01\n",
            " -9.38206166e-02 -9.56144929e-02 -5.59628785e-01 -6.77064538e-01\n",
            " -6.97740689e-02 -4.72086728e-01  1.87952053e-02  1.18226126e-01\n",
            " -5.96052706e-02 -6.83702409e-01  2.42473334e-01  7.23096877e-02\n",
            "  2.92764660e-02 -1.53676584e-01  6.77466020e-02  4.01732102e-02\n",
            "  1.69159591e-01  2.65004426e-01 -5.94622120e-02  3.07570249e-02\n",
            "  1.21732011e-01  1.20068826e-02 -2.62647420e-01  7.38622546e-02\n",
            "  1.53027877e-01 -4.79139596e-01 -6.81054741e-02  7.00676627e-03\n",
            " -5.77893704e-02  2.99621254e-01  6.16581403e-02  7.42193907e-02]\n",
            "[ 6.44574702e-01  5.06261170e-01  3.49338859e-01 -2.44553030e-01\n",
            "  3.10303308e-02  6.99807778e-02 -3.19678813e-01  4.47384119e-01\n",
            "  7.43006527e-01  4.64362890e-01 -1.28887683e-01  4.28523809e-01\n",
            "  2.81163126e-01  1.95438951e-01  4.44652259e-01  1.12232536e-01\n",
            "  1.53528005e-01  5.23777723e-01 -3.50786954e-01  2.87626952e-01\n",
            "  2.43940994e-01  3.28467131e-01  1.02825888e-01  4.78477627e-01\n",
            "  2.51668543e-01  3.16921204e-01  3.08222562e-01  1.54738463e-02\n",
            "  1.74637556e-01  2.15205476e-01  4.83688951e-01  6.98193461e-02\n",
            "  1.10363975e-01  2.62921005e-01  4.73016165e-02  3.38164359e-01\n",
            "  2.28131860e-01  2.44889632e-01  3.97002250e-01 -3.97621356e-02\n",
            " -2.19955310e-01 -3.36758822e-01  1.27014101e-01  4.15845782e-01\n",
            "  5.86132348e-01  1.92165583e-01  1.24600910e-01  6.07471943e-01\n",
            "  3.19669753e-01  2.23737106e-01  2.64986753e-01  2.64439493e-01\n",
            "  2.16914177e-01 -2.77910382e-04 -1.60107478e-01 -8.46006647e-02\n",
            "  6.96831346e-01  1.80321470e-01  2.57379800e-01  4.82226461e-01\n",
            "  5.06391108e-01  1.02747768e-01  2.05310106e-01  2.28046924e-01\n",
            "  5.48530042e-01  4.95061688e-02  4.86672789e-01  4.00228590e-01\n",
            "  6.50345862e-01  2.39637271e-01 -9.35633630e-02 -1.92163140e-01\n",
            "  2.00409859e-01  5.39501905e-01 -2.80498445e-01  5.04200220e-01\n",
            "  5.71502209e-01  7.21688092e-01  2.86919624e-01  4.57828790e-01\n",
            "  1.00071639e-01 -2.22484306e-01  4.81673688e-01  8.14718455e-02\n",
            "  6.39188290e-01  1.18355669e-01  1.95353419e-01 -2.56944805e-01\n",
            "  1.02077581e-01  3.92781645e-01  3.14453363e-01  2.95503348e-01\n",
            "  3.58475387e-01  4.51760590e-01  2.24542722e-01  2.63469875e-01\n",
            "  5.30506372e-01  1.66008323e-01  2.95129746e-01  2.08859116e-01\n",
            "  2.50693828e-01  2.10227281e-01  2.21081764e-01  4.69168156e-01\n",
            "  4.58512604e-01 -1.28149986e-05  3.19658786e-01  2.56475002e-01\n",
            "  4.82463926e-01 -1.45872518e-01  2.00765520e-01  2.15281442e-01\n",
            "  5.51533222e-01 -1.86557807e-02  3.73545647e-01  6.02580667e-01\n",
            "  2.12144047e-01  3.88691187e-01  9.98688638e-02  2.44644582e-01\n",
            "  2.75782019e-01  5.25258183e-01  4.32013184e-01 -1.65057182e-01\n",
            "  3.79128605e-01  6.06466532e-01  4.29884613e-01  1.87236011e-01\n",
            "  2.03649864e-01  5.11132181e-01 -4.21837062e-01  2.14504391e-01\n",
            "  5.34351945e-01  2.59855777e-01  5.74489832e-01  3.83628279e-01\n",
            "  1.06067568e-01  4.18049902e-01  3.48438859e-01  7.67389834e-01\n",
            " -1.85151950e-01  2.21927807e-01  2.17906311e-01  4.76232886e-01\n",
            "  2.76584089e-01  2.45953813e-01  5.28461695e-01  2.40401119e-01\n",
            "  2.02609584e-01 -2.45791465e-01  4.47527289e-01  4.39478070e-01\n",
            "  1.52163744e-01  2.64659911e-01  3.40136066e-02  3.00685227e-01\n",
            "  1.38871938e-01  3.33712608e-01  4.21539903e-01  2.07456797e-02\n",
            " -2.30474502e-01  4.80475843e-01 -9.56618488e-01 -4.05287370e-03\n",
            " -9.58786607e-02  6.82199001e-01  1.12791777e-01  5.02782822e-01\n",
            " -1.08748555e-01  1.86124593e-01  3.57163042e-01 -4.45271075e-01\n",
            "  4.72501099e-01  1.89799562e-01  2.37277523e-01  1.62862584e-01\n",
            "  2.50714511e-01  8.22459236e-02  2.33618975e-01  1.26529485e-01\n",
            "  5.98864436e-01 -1.03897788e-03  1.54965207e-01  2.70689160e-01\n",
            "  5.92381299e-01 -3.33714157e-01  3.48657697e-01  1.15517266e-01\n",
            "  3.26227695e-01  9.78215188e-02  4.03934807e-01  3.78093213e-01\n",
            "  1.41251847e-01  4.72000688e-01  3.38092834e-01  4.42917615e-01\n",
            "  3.41857821e-01 -2.60296434e-01  5.13180494e-01  1.40843213e-01\n",
            "  3.54410321e-01  3.78969789e-01  1.09891996e-01  5.04923344e-01\n",
            "  1.16722092e-01  5.83135784e-01 -4.33476686e-01  6.85359359e-01\n",
            " -2.72677809e-01  4.39760536e-01  1.90382317e-01  6.09122157e-01\n",
            "  2.65776992e-01  3.83863896e-01  3.42710465e-01 -2.57031858e-01\n",
            "  4.15253311e-01  4.31118131e-01  6.37585878e-01  1.99888751e-01\n",
            "  3.23500000e-02  4.35708165e-01  1.22774877e-02 -1.27697021e-01\n",
            "  1.19053937e-01  7.93069303e-02 -2.63268352e-01 -1.70430899e-01\n",
            "  2.82408625e-01 -3.46650690e-01  1.99831784e-01  4.62030441e-01\n",
            "  4.10944819e-01 -4.46780503e-01  5.02588332e-01  2.23937437e-01\n",
            "  3.39350790e-01  3.49142998e-01  3.35078508e-01  1.34472683e-01\n",
            "  6.42046630e-01  4.34449255e-01  1.18670106e-01  2.62516171e-01\n",
            "  3.21337819e-01  2.21595272e-01 -1.81167662e-01  3.38242441e-01\n",
            "  4.26627427e-01  2.69473732e-01  2.04246677e-02  1.55207634e-01\n",
            "  1.10341087e-01  6.81158721e-01  4.14973497e-01  2.48972863e-01]\n",
            "INP: [-0.8159154  -1.1463989   1.7992973  -0.72336125 -0.6114851 ]\n",
            "FINGER: [ 0.6445747   0.40288377  0.06779565 -0.31292638 -0.09155623 -0.03564803\n",
            " -0.4874432   0.11579783  0.6888645   0.3181981  -0.1334835   0.39963007\n",
            "  0.1889437   0.06712434  0.43476894  0.0366262   0.03834337  0.34193745\n",
            " -0.49897307  0.261995   -0.00265998  0.12338503  0.02302736  0.45340458\n",
            "  0.09588252  0.2576562   0.24773578 -0.07624041  0.04432008  0.18307851\n",
            " -0.01412503 -0.09614213  0.0665441   0.03263328 -0.0467554   0.26975942\n",
            "  0.15846184  0.11152902  0.38002184 -0.19825575 -0.29149672 -0.6630576\n",
            "  0.06375544  0.3864344   0.50476384  0.19216558  0.09555588  0.5316917\n",
            "  0.0702939   0.00531326  0.17681271  0.21523744  0.05634245 -0.09491114\n",
            " -0.16370697 -0.1433331   0.55813074  0.02942502  0.11470241 -0.3848657\n",
            "  0.08139163 -0.0094329   0.15626729  0.15861318  0.4827238  -0.01979679\n",
            "  0.19235781  0.3431391   0.59218895 -0.00695592 -0.13672349 -0.21554908\n",
            "  0.15983145  0.34313124 -0.3236911   0.49615145  0.5231153   0.6893238\n",
            "  0.118903    0.4129985   0.10007164 -0.24657407  0.35552034 -0.06404266\n",
            "  0.55809945  0.07728041  0.01517049 -0.5111576  -0.64033866  0.36152282\n",
            "  0.26103944  0.15054733  0.04802773  0.02412152  0.09564669  0.19479814\n",
            "  0.47598037 -0.4078613   0.27978703  0.08835772  0.16825406  0.06698418\n",
            "  0.13425693  0.46916816  0.27137032 -0.02159913  0.2881164   0.12819746\n",
            " -0.34821472 -0.22058949  0.15309814  0.09191139  0.49925262 -0.11850782\n",
            "  0.32312256  0.51859474  0.16050598  0.1728904   0.05039323  0.24042344\n",
            "  0.21482107  0.04516981  0.12969773 -0.2682082   0.32398456  0.5724199\n",
            "  0.37816215  0.00986453  0.13432999  0.14833093 -0.64547545  0.13620928\n",
            "  0.50769377  0.10800806  0.56022495 -0.00546501  0.01817995  0.29995\n",
            "  0.23114903  0.72063833 -0.4302746   0.04169612  0.05031032  0.47533476\n",
            "  0.18850468  0.19016749  0.46103624  0.13385852 -0.03192473 -1.0452085\n",
            "  0.11272558  0.43947807  0.10345241  0.17244238 -0.05553678  0.05812413\n",
            " -0.7356617  -0.18158387 -0.04223006 -0.03780361 -0.27050537  0.45188582\n",
            " -1.2311995  -0.041554   -0.12578124  0.3866189  -0.05490374  0.21680222\n",
            " -0.13261184 -0.05843674  0.30975288 -0.58367586  0.3867486   0.12108764\n",
            "  0.14248918  0.108317    0.216051    0.02649081  0.03288975  0.01654578\n",
            "  0.5031946  -0.04998352  0.08553867 -0.30996743  0.55998147 -0.4260866\n",
            "  0.11093818  0.06880624  0.23643836  0.00292464  0.35676315  0.31894535\n",
            "  0.06619956  0.43320838  0.12818253  0.27837244  0.10812386 -0.36610594\n",
            "  0.498985    0.08308153  0.30557585  0.317529    0.02862813  0.31303677\n",
            "  0.08195015  0.5575128  -0.6688458   0.52715075 -0.38284802  0.3789662\n",
            "  0.19038232  0.5661795   0.23679103  0.11501253  0.07567123 -0.31801313\n",
            "  0.10967847  0.39570943  0.6375859   0.18949766 -0.04746725  0.1341902\n",
            " -0.01917237 -0.12769702  0.06028593 -0.06511556 -0.31421134 -0.67706454\n",
            " -0.04587561 -0.3553774   0.11977355  0.11822613  0.3688751  -0.63382024\n",
            "  0.43466395  0.10170531  0.02927647  0.33720386  0.18332252  0.08224247\n",
            "  0.57453144  0.415698   -0.03081919  0.03149248  0.20083529  0.1561316\n",
            " -0.26264742  0.28590295  0.18637806 -0.4791396  -0.03254728  0.02017735\n",
            "  0.06618957  0.5895759   0.3450916   0.12397107]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length = len(x_train[0])\n",
        "\n",
        "\n",
        "x_train_min = np.zeros(length)\n",
        "x_train_max = np.zeros(length)\n",
        "\n",
        "for indx in range(0,length):\n",
        "  x_train_min[indx] = np.min(x_train[:,indx])\n",
        "  x_train_max[indx] = np.max(x_train[:,indx])\n",
        "\n",
        "print(x_train_min)\n",
        "print(x_train_max)\n",
        "\n",
        "\n",
        "\n",
        "###########\n",
        "rule_neurons_list_5_1 = []\n",
        "rule_neurons = (rule_5_1_neurons.array[0]).split(\",\")\n",
        "for indx in range(0, len(rule_neurons)):\n",
        "    rule_neurons[indx] = (rule_neurons[indx]).strip()\n",
        "    rule_neurons[indx] = (rule_neurons[indx]).replace(\"[\", \"\")\n",
        "    rule_neurons[indx] = (rule_neurons[indx]).replace(\"]\",\"\")\n",
        "    rule_neurons_list_5_1.append(int(rule_neurons[indx]))\n",
        "\n",
        "print(rule_neurons_list_5_1)\n",
        "\n",
        "rule_sig_list_5_1 = []\n",
        "rule_sig = (rule_5_1_signature.array[0]).split(\",\")\n",
        "for indx in range(0, len(rule_sig)):\n",
        "    rule_sig[indx] = (rule_sig[indx]).strip()\n",
        "    rule_sig[indx] = (rule_sig[indx]).replace(\"[\", \"\")\n",
        "    rule_sig[indx] = (rule_sig[indx]).replace(\"]\",\"\")\n",
        "    rule_sig_list_5_1.append(int(rule_sig[indx]))\n",
        "\n",
        "print(rule_sig_list_5_1)\n",
        "\n",
        "fngprnt = (fingerprint_5[0] > 0.0).astype('int')\n",
        "indices = get_suffix_cluster(rule_neurons_list_5_1, rule_sig_list_5_1, fngprnt)\n",
        "print(\"indices:\", len(indices))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x_train_5_1 = []\n",
        "fngprnt_5_1 = []\n",
        "inp_ex_5_1 = []\n",
        "finger_ex_5_1 = []\n",
        "for indx in range(0, len(indices)):\n",
        "    if (indx == 0):\n",
        "      inp_ex_5_1 = x_train[indices[indx]]\n",
        "      finger_ex_5_1 = fingerprint_5[0][indices[indx]]\n",
        "\n",
        "    x_train_5_1.append(x_train[indices[indx]])\n",
        "    fngprnt_5_1.append(fingerprint_5[0][indices[indx]])\n",
        "\n",
        "x_train_5_1= np.array(x_train_5_1)\n",
        "fngprnt_5_1 = np.array(fngprnt_5_1)\n",
        "\n",
        "print(np.shape(x_train_5_1))\n",
        "x_train_min_5_1 = np.zeros(length)\n",
        "x_train_max_5_1 = np.zeros(length)\n",
        "\n",
        "for indx in range(0,length):\n",
        "  x_train_min_5_1[indx] = np.min(x_train_5_1[:,indx])\n",
        "  x_train_max_5_1[indx] = np.max(x_train_5_1[:,indx])\n",
        "\n",
        "print(x_train_min_5_1)\n",
        "print(x_train_max_5_1)\n",
        "\n",
        "print(np.shape(fngprnt_5_1))\n",
        "fngprnt_min_5_1 = np.zeros(len(fngprnt_5_1[0]))\n",
        "fngprnt_max_5_1 = np.zeros(len(fngprnt_5_1[0]))\n",
        "\n",
        "for indx in range(0,len(fngprnt_5_1[0])):\n",
        "  fngprnt_min_5_1[indx] = np.min(fngprnt_5_1[:,indx])\n",
        "  fngprnt_max_5_1[indx] = np.max(fngprnt_5_1[:,indx])\n",
        "\n",
        "print(fngprnt_min_5_1)\n",
        "print(fngprnt_max_5_1)\n",
        "\n",
        "\n",
        "print(\"INP:\", inp_ex_5_1)\n",
        "print(\"FINGER:\", finger_ex_5_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0oHLTpP__SL",
        "outputId": "36219c69-56b1-4bdc-e195-af6728858841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.85240561 -1.1463989  -1.188622   -1.23082471 -0.81692582]\n",
            "[5.4302597  2.1834619  1.79929733 1.31291699 3.59591293]\n",
            "[155, 97, 39, 219, 23, 11]\n",
            "[0, 0, 0, 0, 1, 1]\n",
            "indices: 63\n",
            "(63, 5)\n",
            "[-0.40817672 -1.1463989   0.16952318 -1.23082471 -0.72578561]\n",
            "[ 2.25719643 -0.47028506  1.79929733  1.31291699 -0.46875209]\n",
            "(63, 256)\n",
            "[1.03499733e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 3.83155972e-01 3.03180248e-01 0.00000000e+00 9.93944705e-05\n",
            " 0.00000000e+00 0.00000000e+00 7.14892000e-02 0.00000000e+00\n",
            " 1.08241625e-02 0.00000000e+00 0.00000000e+00 4.21178080e-02\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.52980585e-02\n",
            " 0.00000000e+00 0.00000000e+00 2.50227273e-01 0.00000000e+00\n",
            " 0.00000000e+00 9.90967005e-02 0.00000000e+00 3.38076949e-02\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.00563449e-01\n",
            " 0.00000000e+00 0.00000000e+00 1.05809011e-01 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.68780538e-02\n",
            " 0.00000000e+00 4.34476659e-02 0.00000000e+00 1.39329106e-01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.20166320e-02\n",
            " 0.00000000e+00 5.41380532e-02 0.00000000e+00 0.00000000e+00\n",
            " 4.48633283e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 6.15432337e-02 0.00000000e+00 0.00000000e+00\n",
            " 2.13744938e-01 9.52150524e-02 0.00000000e+00 1.94149032e-01\n",
            " 2.10155383e-01 2.82962136e-02 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.76097506e-01\n",
            " 0.00000000e+00 3.30845416e-01 5.46264015e-02 6.27708286e-02\n",
            " 0.00000000e+00 0.00000000e+00 2.50071347e-01 0.00000000e+00\n",
            " 1.90499648e-01 1.79449990e-02 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 1.63006648e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.03938781e-01\n",
            " 4.03018475e-01 0.00000000e+00 1.31257758e-01 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.17130749e-01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 1.21445999e-01 0.00000000e+00\n",
            " 9.15842038e-03 0.00000000e+00 2.96664298e-01 3.88977051e-01\n",
            " 0.00000000e+00 9.88782346e-02 0.00000000e+00 9.21382755e-03\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 2.83725709e-01 8.54945257e-02 1.09509453e-01 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 2.60979861e-01 0.00000000e+00 2.24788040e-01 0.00000000e+00\n",
            " 0.00000000e+00 1.73237979e-01 0.00000000e+00 2.55589068e-01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.16904065e-01\n",
            " 2.47421581e-02 0.00000000e+00 3.77509385e-01 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 6.32467940e-02\n",
            " 0.00000000e+00 0.00000000e+00 2.67102066e-02 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 6.28047436e-02 0.00000000e+00 9.98320132e-02\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 8.98253322e-02 1.50283501e-01 0.00000000e+00\n",
            " 3.48898977e-01 4.67051491e-02 0.00000000e+00 1.04135789e-01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 1.70546323e-01 0.00000000e+00 0.00000000e+00\n",
            " 2.75009960e-01 0.00000000e+00 2.18085766e-01 7.43301138e-02\n",
            " 0.00000000e+00 0.00000000e+00 1.16737343e-01 0.00000000e+00\n",
            " 0.00000000e+00 1.17699072e-01 0.00000000e+00 2.76375383e-01\n",
            " 1.37700103e-02 0.00000000e+00 1.13688916e-01 0.00000000e+00\n",
            " 9.03445855e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 4.85517904e-02 3.65935192e-02 0.00000000e+00 4.76913005e-02\n",
            " 0.00000000e+00 1.53243139e-01 1.50196746e-01 1.94158658e-01\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 1.36616826e-01 1.80332437e-01 0.00000000e+00\n",
            " 7.85720944e-02 0.00000000e+00 5.45611307e-02 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 9.47817266e-02 4.54666883e-01 0.00000000e+00\n",
            " 1.91895992e-01 2.69480571e-02 0.00000000e+00 5.12733907e-02\n",
            " 7.00245723e-02 0.00000000e+00 0.00000000e+00 1.44692287e-01\n",
            " 5.88015616e-02 0.00000000e+00 1.33958459e-02 0.00000000e+00\n",
            " 7.41603449e-02 8.40146095e-02 1.49921909e-01 0.00000000e+00]\n",
            "[4.56385761e-01 3.52549523e-01 7.18327910e-02 0.00000000e+00\n",
            " 1.27962887e+00 1.99387044e-01 0.00000000e+00 3.59727830e-01\n",
            " 8.39628875e-01 6.33868992e-01 0.00000000e+00 2.27076828e-01\n",
            " 1.30310565e-01 2.95442492e-01 2.82475054e-01 2.82180626e-02\n",
            " 1.00654280e+00 4.03177440e-01 0.00000000e+00 2.95408875e-01\n",
            " 6.76000044e-02 2.23380253e-01 1.86045736e-01 2.54936695e-01\n",
            " 1.50439516e-01 2.75062889e-01 7.02267587e-01 1.04456842e+00\n",
            " 1.96989685e-01 2.87136525e-01 1.04953639e-01 1.60274589e+00\n",
            " 8.67169201e-01 2.13116676e-01 2.29179010e-01 1.26872849e+00\n",
            " 1.47255421e-01 1.58485442e-01 3.87023985e-01 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 1.90708712e-01 3.56441975e-01\n",
            " 3.35105926e-01 5.78010499e-01 6.35454357e-02 6.91031516e-01\n",
            " 9.73450094e-02 4.42842767e-02 2.61524498e-01 5.81892371e-01\n",
            " 5.54181412e-02 1.31791043e+00 0.00000000e+00 3.18068832e-01\n",
            " 8.16805601e-01 4.61032167e-02 2.90028751e-01 2.18210548e-01\n",
            " 1.85993075e-01 1.17269981e+00 0.00000000e+00 5.67984954e-02\n",
            " 6.71720564e-01 1.23696828e+00 2.26582944e-01 4.25872445e-01\n",
            " 1.22000647e+00 9.73831236e-01 0.00000000e+00 1.01560211e+00\n",
            " 4.81603175e-01 2.54738927e-01 0.00000000e+00 9.60164607e-01\n",
            " 2.97313899e-01 7.42999434e-01 3.26438367e-01 3.16213936e-01\n",
            " 7.83112049e-02 0.00000000e+00 1.22011924e+00 7.87490606e-01\n",
            " 2.17513943e+00 2.23484114e-01 9.73595157e-02 0.00000000e+00\n",
            " 0.00000000e+00 5.80366910e-01 2.44657263e-01 2.18320310e-01\n",
            " 1.18625395e-01 8.65646005e-02 8.14647377e-02 4.31041121e-01\n",
            " 6.95122123e-01 0.00000000e+00 8.85263443e-01 1.24435917e-01\n",
            " 1.53172761e-01 3.30646753e-01 8.14530402e-02 4.03972298e-01\n",
            " 3.14079314e-01 2.30535150e-01 3.61973554e-01 2.08024338e-01\n",
            " 8.98804441e-02 0.00000000e+00 9.79566097e-01 2.62265801e-01\n",
            " 4.07758623e-01 6.79910421e-01 8.74577522e-01 1.21452391e+00\n",
            " 0.00000000e+00 4.34629440e-01 3.35177809e-01 3.77367854e-01\n",
            " 3.29790115e-02 2.55463123e-01 6.62723035e-02 0.00000000e+00\n",
            " 5.15652180e-01 3.57146233e-01 4.12549049e-01 9.68177319e-02\n",
            " 2.12108627e-01 1.38188571e-01 9.74341333e-02 2.95062304e-01\n",
            " 5.67064643e-01 2.29587302e-01 1.00778162e+00 2.23307297e-01\n",
            " 1.88962370e-03 4.87242073e-01 2.96344101e-01 9.96157825e-01\n",
            " 0.00000000e+00 1.42106533e-01 4.42615330e-01 3.12356710e-01\n",
            " 2.54603684e-01 2.82296658e-01 7.13424921e-01 2.32601874e-02\n",
            " 1.46762639e-01 0.00000000e+00 6.44667447e-02 3.56986672e-01\n",
            " 0.00000000e+00 2.17226088e-01 1.39369798e+00 0.00000000e+00\n",
            " 0.00000000e+00 5.73968235e-03 1.39119849e-01 5.75257301e-01\n",
            " 0.00000000e+00 3.34942162e-01 0.00000000e+00 1.24440539e+00\n",
            " 2.44535282e-02 2.86839098e-01 2.32091714e-02 3.02997530e-01\n",
            " 4.03904498e-01 1.45019531e+00 7.00759053e-01 0.00000000e+00\n",
            " 7.57936478e-01 8.26947749e-01 4.13249955e-02 1.35410523e+00\n",
            " 1.85801312e-01 1.06033109e-01 2.42030591e-01 1.13825746e-01\n",
            " 4.76374090e-01 1.16948915e+00 2.68333778e-02 9.09336656e-02\n",
            " 8.14563990e-01 0.00000000e+00 8.27239156e-01 3.60451609e-01\n",
            " 3.12458754e-01 3.26874495e-01 7.49407351e-01 2.79094398e-01\n",
            " 2.43041888e-02 6.98407710e-01 2.85534620e-01 1.03447378e+00\n",
            " 2.71549135e-01 0.00000000e+00 4.30982709e-01 0.00000000e+00\n",
            " 3.62536669e-01 1.93372548e-01 6.93755597e-02 4.61809248e-01\n",
            " 1.11381459e+00 3.50664020e-01 0.00000000e+00 3.49726945e-01\n",
            " 0.00000000e+00 3.67763340e-01 7.93746769e-01 7.76366055e-01\n",
            " 2.12707818e-01 1.07189760e-01 2.21793100e-01 0.00000000e+00\n",
            " 1.47713527e-01 4.14174467e-01 6.70976400e-01 0.00000000e+00\n",
            " 1.07735538e+00 0.00000000e+00 8.11411202e-01 0.00000000e+00\n",
            " 7.12578416e-01 6.76771343e-01 0.00000000e+00 0.00000000e+00\n",
            " 1.38261884e-01 0.00000000e+00 3.52365524e-01 9.66939479e-02\n",
            " 8.63721073e-01 0.00000000e+00 3.93138438e-01 1.94376498e-01\n",
            " 5.76741919e-02 7.30309606e-01 1.06763613e+00 1.43613935e-01\n",
            " 7.51988590e-01 2.41521224e-01 1.11353286e-02 5.01507998e-01\n",
            " 2.63550848e-01 2.89178848e-01 0.00000000e+00 7.67212033e-01\n",
            " 4.33949828e-01 0.00000000e+00 7.24434018e-01 1.16837204e-01\n",
            " 9.68777657e-01 6.06053114e-01 1.10242772e+00 1.25520695e-02]\n",
            "INP: [-0.12260102 -1.1463989   1.7992973   1.312917   -0.6448043 ]\n",
            "FINGER: [0.43469602 0.0125438  0.         0.         0.         0.\n",
            " 0.         0.2705942  0.8396289  0.42469066 0.         0.0983721\n",
            " 0.         0.00519128 0.2066215  0.         0.11763179 0.2020722\n",
            " 0.         0.12606318 0.         0.         0.         0.19563212\n",
            " 0.07097296 0.12316573 0.6977021  0.09638012 0.19698969 0.22536159\n",
            " 0.         0.26563507 0.15305942 0.         0.         0.6412158\n",
            " 0.08376867 0.         0.2570983  0.         0.         0.\n",
            " 0.00170675 0.23615292 0.22189254 0.26784292 0.         0.24995582\n",
            " 0.         0.         0.07891244 0.1573103  0.         0.21868841\n",
            " 0.         0.         0.74270487 0.         0.         0.\n",
            " 0.         0.18778725 0.         0.         0.34663475 0.29414585\n",
            " 0.         0.305266   0.5929998  0.20746773 0.         0.23033537\n",
            " 0.48160318 0.07876737 0.         0.41259566 0.08163709 0.74299943\n",
            " 0.08158877 0.12326391 0.02932822 0.         0.46052828 0.\n",
            " 0.8839616  0.03492855 0.         0.         0.         0.3303108\n",
            " 0.16498736 0.         0.         0.         0.         0.23658915\n",
            " 0.61844563 0.         0.2699549  0.         0.         0.31478125\n",
            " 0.         0.4039723  0.         0.08588497 0.14183035 0.\n",
            " 0.         0.         0.47764325 0.         0.10618597 0.\n",
            " 0.5457398  0.68764687 0.         0.25773743 0.         0.21714419\n",
            " 0.         0.         0.         0.         0.5105478  0.33155224\n",
            " 0.11760364 0.         0.         0.         0.         0.07751895\n",
            " 0.56706464 0.         0.4514756  0.         0.         0.25566766\n",
            " 0.03387704 0.54252166 0.         0.         0.         0.25812462\n",
            " 0.03318439 0.         0.69102377 0.         0.02422125 0.\n",
            " 0.         0.35698667 0.         0.07144137 0.4094984  0.\n",
            " 0.         0.         0.         0.05457946 0.         0.14862058\n",
            " 0.         0.2572058  0.         0.         0.         0.17590776\n",
            " 0.18101214 0.17053473 0.20852432 0.         0.58327574 0.08657584\n",
            " 0.         0.40783256 0.03180154 0.03557272 0.         0.\n",
            " 0.23286842 0.36748523 0.         0.         0.45397925 0.\n",
            " 0.31283683 0.117608   0.         0.         0.2475896  0.12194538\n",
            " 0.         0.36755452 0.         0.4579498  0.16085452 0.\n",
            " 0.34828764 0.         0.03463019 0.         0.         0.30521208\n",
            " 0.27744067 0.3257791  0.         0.14868823 0.         0.29702455\n",
            " 0.34245872 0.36594185 0.12945364 0.         0.         0.\n",
            " 0.         0.27765062 0.5090889  0.         0.2541495  0.\n",
            " 0.12160463 0.         0.08428109 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.3035162  0.\n",
            " 0.2793845  0.06898234 0.         0.49398816 0.7053766  0.\n",
            " 0.274064   0.19747828 0.         0.10923347 0.20287469 0.21552417\n",
            " 0.         0.2079036  0.12068805 0.         0.19474104 0.\n",
            " 0.15425941 0.15878035 0.328975   0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROOFS WITH MARABOU**"
      ],
      "metadata": {
        "id": "8MJOVHlVB4Q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Marabou_bld')\n",
        "!pwd\n",
        "!ls -lt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MntqNSD4Bv6F",
        "outputId": "a2db1c62-69fb-464b-dcc4-a3a6cc4b5697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Marabou_bld\n",
            "total 54578\n",
            "-rw------- 1 root root   237800 Dec 27 01:00 cnn_max_mnist2.h5\n",
            "-rw------- 1 root root  7840128 Dec 27 01:00 x_test_npy.npy\n",
            "-rw------- 1 root root 47040128 Dec 27 01:00 x_train_npy.npy\n",
            "-rw------- 1 root root    10128 Dec 27 01:00 y_test_npy.npy\n",
            "-rw------- 1 root root    60128 Dec 27 01:00 y_train_npy.npy\n",
            "-rw------- 1 root root     7194 Dec 16 18:56 evaluateWithMarabou.log\n",
            "drwx------ 2 root root     4096 Dec 12 17:57 ProphecyPlus\n",
            "-rw------- 1 root root   305212 Nov 25 05:34 mnist_cnn.onnx\n",
            "-rw------- 1 root root   305212 Nov 25 05:33 REDPropiaFinal.onnx\n",
            "drwx------ 2 root root     4096 Nov 25 05:33 tmp_model\n",
            "drwx------ 2 root root     4096 Nov 24 21:00 tools\n",
            "drwx------ 2 root root     4096 Nov 24 20:59 build\n",
            "drwx------ 2 root root     4096 Nov 24 20:59 resources\n",
            "drwx------ 2 root root     4096 Nov 24 20:37 maraboupy\n",
            "-rw------- 1 root root     2092 Nov 24 20:06 AUTHORS\n",
            "-rw------- 1 root root     2274 Nov 24 20:06 CHANGELOG.md\n",
            "-rw------- 1 root root    16073 Nov 24 20:06 CMakeLists.txt\n",
            "-rw------- 1 root root     2541 Nov 24 20:06 COPYING\n",
            "drwx------ 2 root root     4096 Nov 24 20:06 deps\n",
            "-rw------- 1 root root      209 Nov 24 20:06 MANIFEST.in\n",
            "-rw------- 1 root root     1953 Nov 24 20:06 pyproject.toml\n",
            "-rw------- 1 root root    11828 Nov 24 20:06 README.md\n",
            "drwx------ 2 root root     4096 Nov 24 20:06 regress\n",
            "-rw------- 1 root root     1993 Nov 24 20:06 setup.py\n",
            "drwx------ 2 root root     4096 Nov 24 20:06 src\n",
            "-rw------- 1 root root      609 Nov 24 20:06 THANKS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = os.environ['PATH']\n",
        "print(path)\n",
        "#os.environ['PATH'] = '/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/content/Marabou/build/Marabou:/content/Marabou/build/Marabou/build:/content/Marabou/build/Marabou/build/bin:/content/Marabou/build/Marabou:/content/Marabou/build/Marabou/build:/content/Marabou/build/Marabou/build/bin'\n",
        "print(os.environ['PATH'])\n",
        "os.environ['PATH'] = path + ':/content/drive/MyDrive/Marabou_bld:/content/drive/MyDrive/Marabou_bld/build:/content/drive/MyDrive/Marabou_bld/build/bin'\n",
        "print(os.environ['PATH'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLPkIxlQB80M",
        "outputId": "bcfeb935-d786-4c1f-c3c1-1692dedd3a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n",
            "/opt/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n",
            "/opt/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/content/drive/MyDrive/Marabou_bld:/content/drive/MyDrive/Marabou_bld/build:/content/drive/MyDrive/Marabou_bld/build/bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROVE RULE FOR ROBUSTNESS OF OP**"
      ],
      "metadata": {
        "id": "W1qxk6iJCAKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from maraboupy import Marabou\n",
        "from maraboupy.MarabouCore import *\n",
        "from maraboupy.MarabouPythonic import *\n",
        "\n",
        "options = Marabou.createOptions(verbosity = 1, numWorkers=1, numBlasThreads=1,snc=True)\n",
        "\n",
        "filename = \"/content/drive/MyDrive/FAA_CaseStudy/renamed_model.onnx\"\n",
        "network_a = Marabou.read_onnx(filename)\n",
        "\n",
        "\n",
        "print(\"INPUT VARS\")\n",
        "invars = network_a.inputVars[0][0].flatten()\n",
        "\n",
        "\n",
        "\n",
        "for indx in range(0,len(invars)):\n",
        "    i = invars[indx]\n",
        "    v = Var(i)\n",
        "    network_a.setLowerBound(i,x_train_min_4_1[i])\n",
        "    network_a.setUpperBound(i,x_train_max_4_1[i])\n",
        "    #network_a.setLowerBound(i,inp_ex_4_1[indx])\n",
        "    #network_a.setUpperBound(i,inp_ex_4_1[indx])\n",
        "\n",
        "\n",
        "print(\"LAYER VARS MAP\")\n",
        "print(network_a.layerNameToVariables)\n",
        "\n",
        "dense_4_neurons = network_a.layerNameToVariables[\"layer_4_output_0\"][0]\n",
        "print(np.shape(dense_4_neurons))\n",
        "print(len(dense_4_neurons))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for indx in range(0, len(dense_4_neurons)):\n",
        "    neuron_indx = dense_4_neurons[indx] - dense_4_neurons[0]\n",
        "    network_a.setLowerBound(dense_4_neurons[indx], fngprnt_min_4_1[neuron_indx])\n",
        "    network_a.setUpperBound(dense_4_neurons[indx], fngprnt_max_4_1[neuron_indx])\n",
        "    #network_a.setLowerBound(dense_4_neurons[indx], finger_ex_4_1[neuron_indx] - 0.5 )\n",
        "    #network_a.setUpperBound(dense_4_neurons[indx], finger_ex_4_1[neuron_indx] + 0.5 )\n",
        "\n",
        "    if (neuron_indx in rule_neurons_list_4_1):\n",
        "      v = Var(dense_4_neurons[indx])\n",
        "\n",
        "      for indx in range(0, len(rule_neurons_list_4_1)):\n",
        "        if (rule_neurons_list_4_1[indx] == neuron_indx):\n",
        "          index = indx\n",
        "          sig_indx = (2*index) + 1\n",
        "          print(\"N:\", neuron_indx, index)\n",
        "          print(\"OP:\", rule_sig_list_4_1[sig_indx-1])\n",
        "          print(\"VAL:\", rule_sig_list_4_1[sig_indx])\n",
        "         # if (rule_sig_list_4_1[sig_indx-1] == '<='):\n",
        "         #   network_a.addConstraint(float(rule_sig_list_4_1[sig_indx]) >= v)\n",
        "         # else:\n",
        "         #   network_a.addConstraint(v >= float(rule_sig_list_4_1[sig_indx]))\n",
        "\n",
        "\n",
        "\n",
        "print(\"OUTPUT VARS\")\n",
        "outvars = network_a.outputVars[0].flatten()\n",
        "print(outvars)\n",
        "label_var = Var(outvars[0])\n",
        "# |op| >= OP_X + 0.19200696 should be UNSAT\n",
        "#(-0.15859113982634868 - 0.19200696) <= OP <= (-0.15859113982634868 + 0.19200696)\n",
        "# CONSTRAINT 1\n",
        "network_a.addConstraint(label_var >= (0.2 + -0.15859113982634868))\n",
        "\n",
        "# CONSTRAINT 2\n",
        "#network_a.addConstraint((-0.19200696 + -0.15859113982634868) >= label_var)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gh5vTCTB_xX",
        "outputId": "87d4e7ab-3d12-4668-a0d7-7bb505976ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT VARS\n",
            "LAYER VARS MAP\n",
            "{'layer_0_input_0': array([[0, 1, 2, 3, 4]]), 'layer_0_output_0': array([[  5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,  16,  17,\n",
            "         18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,\n",
            "         31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
            "         44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
            "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
            "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
            "         83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,\n",
            "         96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,\n",
            "        109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
            "        122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,\n",
            "        135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,\n",
            "        148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,\n",
            "        161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,\n",
            "        174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
            "        187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199,\n",
            "        200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
            "        213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
            "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
            "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
            "        252, 253, 254, 255, 256, 257, 258, 259, 260]]), 'layer_1_output_0': array([[261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n",
            "        274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n",
            "        287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n",
            "        300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n",
            "        313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
            "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
            "        339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
            "        352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
            "        365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
            "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n",
            "        391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
            "        404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
            "        417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n",
            "        430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
            "        443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n",
            "        456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n",
            "        469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
            "        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
            "        495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507,\n",
            "        508, 509, 510, 511, 512, 513, 514, 515, 516]]), 'layer_2_output_0': array([[517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529,\n",
            "        530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542,\n",
            "        543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555,\n",
            "        556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568,\n",
            "        569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581,\n",
            "        582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594,\n",
            "        595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607,\n",
            "        608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620,\n",
            "        621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633,\n",
            "        634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646,\n",
            "        647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659,\n",
            "        660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672,\n",
            "        673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685,\n",
            "        686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698,\n",
            "        699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711,\n",
            "        712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724,\n",
            "        725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737,\n",
            "        738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750,\n",
            "        751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763,\n",
            "        764, 765, 766, 767, 768, 769, 770, 771, 772]]), 'layer_3_output_0': array([[ 773,  774,  775,  776,  777,  778,  779,  780,  781,  782,  783,\n",
            "         784,  785,  786,  787,  788,  789,  790,  791,  792,  793,  794,\n",
            "         795,  796,  797,  798,  799,  800,  801,  802,  803,  804,  805,\n",
            "         806,  807,  808,  809,  810,  811,  812,  813,  814,  815,  816,\n",
            "         817,  818,  819,  820,  821,  822,  823,  824,  825,  826,  827,\n",
            "         828,  829,  830,  831,  832,  833,  834,  835,  836,  837,  838,\n",
            "         839,  840,  841,  842,  843,  844,  845,  846,  847,  848,  849,\n",
            "         850,  851,  852,  853,  854,  855,  856,  857,  858,  859,  860,\n",
            "         861,  862,  863,  864,  865,  866,  867,  868,  869,  870,  871,\n",
            "         872,  873,  874,  875,  876,  877,  878,  879,  880,  881,  882,\n",
            "         883,  884,  885,  886,  887,  888,  889,  890,  891,  892,  893,\n",
            "         894,  895,  896,  897,  898,  899,  900,  901,  902,  903,  904,\n",
            "         905,  906,  907,  908,  909,  910,  911,  912,  913,  914,  915,\n",
            "         916,  917,  918,  919,  920,  921,  922,  923,  924,  925,  926,\n",
            "         927,  928,  929,  930,  931,  932,  933,  934,  935,  936,  937,\n",
            "         938,  939,  940,  941,  942,  943,  944,  945,  946,  947,  948,\n",
            "         949,  950,  951,  952,  953,  954,  955,  956,  957,  958,  959,\n",
            "         960,  961,  962,  963,  964,  965,  966,  967,  968,  969,  970,\n",
            "         971,  972,  973,  974,  975,  976,  977,  978,  979,  980,  981,\n",
            "         982,  983,  984,  985,  986,  987,  988,  989,  990,  991,  992,\n",
            "         993,  994,  995,  996,  997,  998,  999, 1000, 1001, 1002, 1003,\n",
            "        1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014,\n",
            "        1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025,\n",
            "        1026, 1027, 1028]]), 'layer_4_output_0': array([[1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039,\n",
            "        1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050,\n",
            "        1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061,\n",
            "        1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072,\n",
            "        1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083,\n",
            "        1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094,\n",
            "        1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105,\n",
            "        1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116,\n",
            "        1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127,\n",
            "        1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138,\n",
            "        1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149,\n",
            "        1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160,\n",
            "        1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171,\n",
            "        1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182,\n",
            "        1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193,\n",
            "        1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204,\n",
            "        1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215,\n",
            "        1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226,\n",
            "        1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237,\n",
            "        1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248,\n",
            "        1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,\n",
            "        1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270,\n",
            "        1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281,\n",
            "        1282, 1283, 1284]]), 'layer_5_output_0': array([[1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295,\n",
            "        1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306,\n",
            "        1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317,\n",
            "        1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328,\n",
            "        1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339,\n",
            "        1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350,\n",
            "        1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361,\n",
            "        1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372,\n",
            "        1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383,\n",
            "        1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394,\n",
            "        1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405,\n",
            "        1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416,\n",
            "        1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427,\n",
            "        1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438,\n",
            "        1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449,\n",
            "        1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460,\n",
            "        1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471,\n",
            "        1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482,\n",
            "        1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493,\n",
            "        1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504,\n",
            "        1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515,\n",
            "        1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526,\n",
            "        1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537,\n",
            "        1538, 1539, 1540]]), 'layer_6_output_0': array([[1541]])}\n",
            "(256,)\n",
            "256\n",
            "N: 0 5\n",
            "OP: >\n",
            "VAL: -0.12406855449080467\n",
            "N: 29 0\n",
            "OP: <=\n",
            "VAL: 0.2756440043449402\n",
            "N: 70 6\n",
            "OP: >\n",
            "VAL: -0.15119200199842453\n",
            "N: 76 9\n",
            "OP: >\n",
            "VAL: 0.44639018177986145\n",
            "N: 86 3\n",
            "OP: <=\n",
            "VAL: 0.371839240193367\n",
            "N: 144 8\n",
            "OP: >\n",
            "VAL: 0.14457079768180847\n",
            "N: 147 7\n",
            "OP: >\n",
            "VAL: 0.07985635101795197\n",
            "N: 181 2\n",
            "OP: >\n",
            "VAL: -0.05165771581232548\n",
            "N: 192 4\n",
            "OP: <=\n",
            "VAL: 0.3212895691394806\n",
            "N: 193 10\n",
            "OP: <=\n",
            "VAL: 0.4770570695400238\n",
            "N: 215 1\n",
            "OP: >\n",
            "VAL: -0.5447605848312378\n",
            "OUTPUT VARS\n",
            "[1541]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(network_a.getInputQuery())\n",
        "sat_unsat,vals, stats = network_a.solve(options = options)\n",
        "\n",
        "print(\"sat_unsat:\", sat_unsat)\n",
        "print(\"vals:\", vals)\n",
        "print(\"stats:\", stats)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SfKz8RVDmGJ",
        "outputId": "c0406456-e941-4e4c-8cda-4489cf8da5d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sat\n",
            "input 0 = -0.2812548182892106\n",
            "input 1 = -1.146398901939392\n",
            "input 2 = -0.916992859677764\n",
            "input 3 = -1.2308247089385986\n",
            "input 4 = -0.785624623298645\n",
            "output 0 = 1.210201327984187\n",
            "sat_unsat: sat\n",
            "vals: {0: -0.2812548182892106, 1: -1.146398901939392, 2: -0.916992859677764, 3: -1.2308247089385986, 4: -0.785624623298645, 5: 0.35211024161175136, 6: -0.243502789936913, 7: 0.1831146108695369, 8: -0.6475721531250953, 9: 1.0281109293753126, 10: -0.07479665484421355, 11: 0.3654850064524065, 12: -0.35810033865097357, 13: -0.0106931621604541, 14: 0.3131653263426629, 15: 0.1956856006736597, 16: -0.10375635485787021, 17: -0.511471247275848, 18: 0.6220272353853596, 19: -0.32928674362726584, 20: 0.35747948003016405, 21: -0.004419812058303954, 22: 0.18083502627821432, 23: 0.7972320467129479, 24: -0.09725189172460878, 25: -0.22420457105205405, 26: -0.9118781713665579, 27: -0.2624909543700713, 28: 0.09284481315527893, 29: -0.13310001887944856, 30: 0.2960197005310702, 31: -1.1624097346319564, 32: 0.3717646653842853, 33: -0.11597166676751888, 34: -0.5444202132309266, 35: -0.21681902217939467, 36: -0.08705614577056457, 37: -0.3726320176907363, 38: 1.1435084489898641, 39: -0.7257437516748574, 40: -0.39185540351285697, 41: 0.81113533751179, 42: 1.1336000355772502, 43: 0.1267125965142947, 44: -1.0151076321215002, 45: -0.25404121125487666, 46: -0.22069153791467114, 47: -0.5500151748371186, 48: 0.1422076263446094, 49: 0.1121903674378087, 50: -0.46854607553117406, 51: -0.06647307942039338, 52: -0.4449474550770546, 53: 0.23332267058252934, 54: 0.7069506669497965, 55: -0.38927231387361466, 56: -0.37988650977679667, 57: -1.4042774930272095, 58: 0.1411720553100476, 59: -0.8549836626498356, 60: 1.10236182924602, 61: -0.3116578614013274, 62: 0.09313415621398707, 63: -0.534559792709579, 64: 0.8710814953108559, 65: -0.029437996151060138, 66: 0.07555774491659609, 67: 0.16876287546076604, 68: -0.48785797039059603, 69: -0.05871517182103398, 70: 0.4745023048712505, 71: -0.4575164643584751, 72: 0.3498514871113766, 73: 0.3583018080932511, 74: 1.2380416155756435, 75: 0.16581984998152322, 76: -1.1356575186190163, 77: -0.008452623971293996, 78: 0.6051155220629241, 79: 0.36971094609836647, 80: -0.6041876812915343, 81: 0.17284988542047855, 82: 0.20371315552987895, 83: -0.4039157693409829, 84: -1.081555622004088, 85: 0.2364826233815666, 86: 0.7461038572015208, 87: -0.2497105249705894, 88: 0.8227270555164273, 89: -0.5955951586465653, 90: 0.3385519916477976, 91: 0.3022151166359029, 92: -0.5668483822494673, 93: 0.09049016085470267, 94: 0.41323492360389125, 95: -1.3095248846269953, 96: 0.21137765010390036, 97: -0.3177376004747139, 98: 0.6808974735449478, 99: -0.469994443693798, 100: 0.7068946659436508, 101: 0.016845094852837694, 102: -0.14614848312520085, 103: 0.3361557570361198, 104: 0.3232492893266126, 105: 1.4862811972201437, 106: 0.35639818777131294, 107: -0.4655911955227573, 108: 1.2901459342745734, 109: 0.7535007087083164, 110: -0.05132406915392762, 111: -0.6776645264726405, 112: 0.21772191714771305, 113: 1.3873087245147955, 114: -0.15733667640639326, 115: 0.4526992681705282, 116: 0.023910488686173965, 117: 0.34929172108830464, 118: 0.9058376302207867, 119: 0.4905406881100034, 120: 0.20548372973833587, 121: -1.1221849017449124, 122: -0.7094849963940436, 123: -0.7552265970259172, 124: -0.40550846336330887, 125: -0.45811332957179557, 126: -0.6675274995295822, 127: -0.18585007512494417, 128: -1.36575936152061, 129: -0.7013791792582864, 130: -0.8110386671680999, 131: 0.9258719786992223, 132: 0.6944096250014188, 133: -1.1933320432295544, 134: 0.8787181095698773, 135: 0.8760609253486538, 136: 0.20795553144748952, 137: -0.49762699178862796, 138: 0.1894192491106421, 139: -0.02247181864133374, 140: 0.15301363033309018, 141: -0.00470313813733976, 142: 0.8591221260868708, 143: 1.253355711216006, 144: -0.9782673687149511, 145: 0.3437041424304352, 146: -1.091357155704882, 147: 0.37842865809270065, 148: 0.20447670662519257, 149: -0.10306746920906185, 150: 0.2306345674754762, 151: -0.4390415485693754, 152: 0.2305906077679465, 153: 0.5204333243309469, 154: -0.5670135213106666, 155: -0.11965546594652027, 156: -0.652478673228098, 157: 0.8980305262454282, 158: 0.17426245088641013, 159: 0.1575468464033183, 160: 0.6353794209298431, 161: 0.673979270066755, 162: -0.00906206100443152, 163: -0.25255145579799343, 164: -0.3860341739332052, 165: -0.9152978026059975, 166: 0.44098304264898747, 167: 0.5231999750782892, 168: -1.4971761523074316, 169: -1.0430900092152506, 170: 1.0169307887104642, 171: -0.2831753861269535, 172: 0.07551385067780958, 173: 0.09668419742198592, 174: 0.3942964122020803, 175: 0.8156639065304773, 176: 1.6582418838733137, 177: 0.151930346135359, 178: 0.14535776109366488, 179: -0.29002791351170076, 180: 1.094241372852251, 181: -0.23380511206554525, 182: -1.1028024890760433, 183: -0.9604352577572346, 184: -0.3677222599579535, 185: 0.3913492655355465, 186: 0.3750312800198978, 187: -0.6314231408097771, 188: -0.09840632773197523, 189: -0.5992268416028458, 190: -0.96658432004738, 191: 0.192270159471627, 192: -0.2718739456887618, 193: -1.3114022526224287, 194: 0.18063275125097195, 195: -0.2367111010920373, 196: -0.8031102463139238, 197: 1.4010844946653538, 198: -0.6344278260342322, 199: 0.7171505289540172, 200: -0.7602462278518543, 201: -0.40155374636291896, 202: 0.18635739958162095, 203: -0.35075565628496963, 204: 0.2476949816789277, 205: 0.8189471162431351, 206: 0.6645755786071506, 207: -0.6806933939746632, 208: 0.11818150093111726, 209: 0.533164814766552, 210: 0.6186974175123077, 211: -0.5738206420012236, 212: 0.5299781481723093, 213: -0.9556813116802193, 214: -0.23561899292700905, 215: -0.028336116717277413, 216: 0.5849812036223534, 217: 0.38242853923566567, 218: 1.1853453378131367, 219: 0.10566102688499956, 220: -0.08301555566983168, 221: -1.3167642737782008, 222: 0.4113694866232118, 223: 0.1466231460378325, 224: 0.614881559562966, 225: 0.1582171666889441, 226: -1.4655966114637162, 227: 0.11181385233372218, 228: 0.3364023712398808, 229: -0.8395386963538364, 230: 0.5362558975762443, 231: -0.38466674780025917, 232: -0.2840861662070808, 233: -0.4525615805495407, 234: 1.0311953331862216, 235: 0.4856837736827704, 236: 0.17157596866430522, 237: -0.3093870534233979, 238: 1.2820195477195204, 239: 0.6701465111301533, 240: -0.1956663501801548, 241: -0.567012212828018, 242: -0.35530637415852356, 243: -0.17269206119465497, 244: -0.42652412385165933, 245: -0.942163260982642, 246: 1.0494420953846404, 247: -0.5656028410650985, 248: -0.34770729339615486, 249: -0.2881326214139688, 250: 0.9814873991607238, 251: -0.7511826315161018, 252: 0.7412925282736558, 253: 1.124289923680987, 254: -0.02929622318475389, 255: -0.1274700813188812, 256: -0.4710891862716116, 257: -0.07389054290063335, 258: -0.8208140864686099, 259: -0.2804404478673256, 260: 0.7912895802664586, 261: 0.35211024161175136, 262: 0.0, 263: 0.1831146108695369, 264: 0.0, 265: 1.0281109293753126, 266: 0.0, 267: 0.3654850064524065, 268: 0.0, 269: 0.0, 270: 0.3131653263426629, 271: 0.1956856006736597, 272: 0.0, 273: 0.0, 274: 0.6220272353853596, 275: 0.0, 276: 0.35747948003016405, 277: 0.0, 278: 0.18083502627821432, 279: 0.7972320467129479, 280: 0.0, 281: 0.0, 282: 0.0, 283: 0.0, 284: 0.09284481315527893, 285: 0.0, 286: 0.2960197005310702, 287: 0.0, 288: 0.3717646653842853, 289: 0.0, 290: 0.0, 291: 0.0, 292: 0.0, 293: 0.0, 294: 1.1435084489898641, 295: 0.0, 296: 0.0, 297: 0.81113533751179, 298: 1.1336000355772502, 299: 0.1267125965142947, 300: 0.0, 301: 0.0, 302: 0.0, 303: 0.0, 304: 0.1422076263446094, 305: 0.1121903674378087, 306: 0.0, 307: 0.0, 308: 0.0, 309: 0.23332267058252934, 310: 0.7069506669497965, 311: 0.0, 312: 0.0, 313: 0.0, 314: 0.1411720553100476, 315: 0.0, 316: 1.10236182924602, 317: 0.0, 318: 0.09313415621398707, 319: 0.0, 320: 0.8710814953108559, 321: 0.0, 322: 0.07555774491659609, 323: 0.16876287546076604, 324: 0.0, 325: 0.0, 326: 0.4745023048712505, 327: 0.0, 328: 0.3498514871113766, 329: 0.3583018080932511, 330: 1.2380416155756435, 331: 0.16581984998152322, 332: 0.0, 333: 0.0, 334: 0.6051155220629241, 335: 0.36971094609836647, 336: 0.0, 337: 0.17284988542047855, 338: 0.20371315552987895, 339: 0.0, 340: 0.0, 341: 0.2364826233815666, 342: 0.7461038572015208, 343: 0.0, 344: 0.8227270555164273, 345: 0.0, 346: 0.3385519916477976, 347: 0.3022151166359029, 348: 0.0, 349: 0.09049016085470267, 350: 0.41323492360389125, 351: 0.0, 352: 0.21137765010390036, 353: 0.0, 354: 0.6808974735449478, 355: 0.0, 356: 0.7068946659436508, 357: 0.016845094852837694, 358: 0.0, 359: 0.3361557570361198, 360: 0.3232492893266126, 361: 1.4862811972201437, 362: 0.35639818777131294, 363: 0.0, 364: 1.2901459342745734, 365: 0.7535007087083164, 366: 0.0, 367: 0.0, 368: 0.21772191714771305, 369: 1.3873087245147955, 370: 0.0, 371: 0.4526992681705282, 372: 0.023910488686173965, 373: 0.34929172108830464, 374: 0.9058376302207867, 375: 0.4905406881100034, 376: 0.20548372973833587, 377: 0.0, 378: 0.0, 379: 0.0, 380: 0.0, 381: 0.0, 382: 0.0, 383: 0.0, 384: 0.0, 385: 0.0, 386: 0.0, 387: 0.9258719786992223, 388: 0.6944096250014188, 389: 0.0, 390: 0.8787181095698773, 391: 0.8760609253486538, 392: 0.20795553144748952, 393: 0.0, 394: 0.1894192491106421, 395: 0.0, 396: 0.15301363033309018, 397: 0.0, 398: 0.8591221260868708, 399: 1.253355711216006, 400: 0.0, 401: 0.3437041424304352, 402: 0.0, 403: 0.37842865809270065, 404: 0.20447670662519257, 405: 0.0, 406: 0.2306345674754762, 407: 0.0, 408: 0.2305906077679465, 409: 0.5204333243309469, 410: 0.0, 411: 0.0, 412: 0.0, 413: 0.8980305262454282, 414: 0.17426245088641013, 415: 0.1575468464033183, 416: 0.6353794209298431, 417: 0.673979270066755, 418: 0.0, 419: 0.0, 420: 0.0, 421: 0.0, 422: 0.44098304264898747, 423: 0.5231999750782892, 424: 0.0, 425: 0.0, 426: 1.0169307887104642, 427: 0.0, 428: 0.07551385067780958, 429: 0.09668419742198592, 430: 0.3942964122020803, 431: 0.8156639065304773, 432: 1.6582418838733137, 433: 0.151930346135359, 434: 0.14535776109366488, 435: 0.0, 436: 1.094241372852251, 437: 0.0, 438: 0.0, 439: 0.0, 440: 0.0, 441: 0.3913492655355465, 442: 0.3750312800198978, 443: 0.0, 444: 0.0, 445: 0.0, 446: 0.0, 447: 0.192270159471627, 448: 0.0, 449: 0.0, 450: 0.18063275125097195, 451: 0.0, 452: 0.0, 453: 1.4010844946653538, 454: 0.0, 455: 0.7171505289540172, 456: 0.0, 457: 0.0, 458: 0.18635739958162095, 459: 0.0, 460: 0.2476949816789277, 461: 0.8189471162431351, 462: 0.6645755786071506, 463: 0.0, 464: 0.11818150093111726, 465: 0.533164814766552, 466: 0.6186974175123077, 467: 0.0, 468: 0.5299781481723093, 469: 0.0, 470: 0.0, 471: 0.0, 472: 0.5849812036223534, 473: 0.38242853923566567, 474: 1.1853453378131367, 475: 0.10566102688499956, 476: 0.0, 477: 0.0, 478: 0.4113694866232118, 479: 0.1466231460378325, 480: 0.614881559562966, 481: 0.1582171666889441, 482: 0.0, 483: 0.11181385233372218, 484: 0.3364023712398808, 485: 0.0, 486: 0.5362558975762443, 487: 0.0, 488: 0.0, 489: 0.0, 490: 1.0311953331862216, 491: 0.4856837736827704, 492: 0.17157596866430522, 493: 0.0, 494: 1.2820195477195204, 495: 0.6701465111301533, 496: 0.0, 497: 0.0, 498: 0.0, 499: 0.0, 500: 0.0, 501: 0.0, 502: 1.0494420953846404, 503: 0.0, 504: 0.0, 505: 0.0, 506: 0.9814873991607238, 507: 0.0, 508: 0.7412925282736558, 509: 1.124289923680987, 510: 0.0, 511: 0.0, 512: 0.0, 513: 0.0, 514: 0.0, 515: 0.0, 516: 0.7912895802664586, 517: 0.10673025784980747, 518: -0.5808470424056831, 519: 0.09756770810259428, 520: -0.4533075726086353, 521: 0.1399021532230049, 522: 0.06249670027679663, 523: 0.6245967162385384, 524: -0.41667343027605996, 525: -0.23627760438659468, 526: 0.008717547631692135, 527: -0.3927343563697044, 528: 0.18600618526299373, 529: 0.9275031554587729, 530: 0.6196354472763506, 531: 0.2371771755616079, 532: -0.09871670884694375, 533: 0.6978747461095787, 534: -0.07894835432730152, 535: 0.08085521121544328, 536: 0.15824971110737424, 537: -0.2548173181270751, 538: 0.13075247033675585, 539: -0.613777823960748, 540: 0.2018045841901913, 541: 0.4413299575151099, 542: -0.5751709629608922, 543: -0.3378688576269666, 544: 0.1911757950756855, 545: 0.5089526738581829, 546: 0.038428407185695145, 547: 0.5798273645573049, 548: 0.5042882284149088, 549: 0.5085208061823157, 550: -0.017808034455870123, 551: -0.1220803989856227, 552: 0.19113828278737865, 553: -0.26687130012812266, 554: -0.8971158688527096, 555: 0.263319902405629, 556: 0.15218724055930224, 557: 0.18315959743907995, 558: -0.4169298856774364, 559: 0.6802061825769906, 560: 0.6756183311781799, 561: 0.3434869791349063, 562: 0.56947701649553, 563: -0.015968939594633177, 564: 0.30098619612454564, 565: -0.20611378394326443, 566: -0.19791290251811008, 567: 0.7442019540695254, 568: 0.5563850653204351, 569: 0.26679791004671355, 570: 0.36259334378143154, 571: -0.37505842350965735, 572: 0.718035685163168, 573: -0.21842179708721698, 574: -0.537304093741851, 575: -0.05572563151104585, 576: 0.641963771178244, 577: -0.22284192008735343, 578: -0.14735293653707146, 579: 0.03427498201887731, 580: -0.332394127807609, 581: 0.32320274607470384, 582: -0.3678138095350413, 583: 0.8472386956283918, 584: -0.7960466124729563, 585: 0.10850186314065563, 586: -1.236474626303825, 587: 0.04514083510777504, 588: 0.1468137988919724, 589: 0.037585192577901355, 590: -0.25199847298387124, 591: 0.02094153852279028, 592: -0.03835929721325435, 593: 0.32943731093201234, 594: 0.7555753462315463, 595: -0.3796931429255005, 596: 0.03229794393483452, 597: 0.3207413772046045, 598: 0.3077210897263394, 599: 0.06166118453825927, 600: 0.5472282966213969, 601: -0.01970612525153666, 602: 0.6232099034959847, 603: -1.0357446133122263, 604: 0.10058825446666678, 605: 0.1925530663534129, 606: -0.9006638495587228, 607: -0.6107623930829904, 608: 0.13514094529504783, 609: 0.040698732441307645, 610: 0.9728774079200847, 611: 0.102982289072475, 612: 0.7064387331853232, 613: 0.05348943945170369, 614: 0.29569564939437, 615: 0.05640240304450482, 616: -0.5136727914847248, 617: -0.7396424569179338, 618: -0.44271012206133675, 619: -0.27504197457701574, 620: -0.047692096427604844, 621: 0.293443180803036, 622: 0.6966331597495969, 623: -0.079413414003098, 624: 0.10365917230661977, 625: 0.5475985578608727, 626: 0.16076581913075005, 627: -0.19783492233239725, 628: 0.4193929855575453, 629: 0.29193237580229253, 630: 0.027730720684207098, 631: -0.47340734619612623, 632: 0.3029188025197115, 633: -0.15945200370352697, 634: -0.07065457366555886, 635: -0.10263475270629592, 636: 0.5089791776226374, 637: 0.58531208529332, 638: 0.08876105207408509, 639: 0.4861193580903679, 640: 0.0928533721683201, 641: -0.37873794433594626, 642: 0.9260115095728837, 643: -0.0037399285325484845, 644: -0.0811328520898584, 645: -0.14096755295208035, 646: 0.193077203915536, 647: 0.18488967180596944, 648: 0.31183893049338496, 649: 0.7112645718852565, 650: -0.37897547848311536, 651: 0.012005005323396756, 652: 0.4746987918040965, 653: 0.2571317870979042, 654: 0.16776908747634997, 655: 0.1907531597299847, 656: 0.20081976219488715, 657: 0.46937609162185906, 658: -0.23697982922889513, 659: -0.7482738887498657, 660: 0.4343865041543517, 661: -0.28747116821625074, 662: 0.29241301939890296, 663: -0.07497248677205547, 664: 0.14687259879402678, 665: 0.2992883840642076, 666: 0.5873134142681155, 667: 0.014961656923096991, 668: 0.24212347975058024, 669: 0.4603362465229334, 670: 0.42954727350660016, 671: -0.34482020641115346, 672: 0.7519142073341789, 673: -0.059234987696588595, 674: -0.3698855907027019, 675: 0.5174167611910483, 676: -0.2457482305067107, 677: 0.035544611418218755, 678: 0.2851456889761576, 679: -0.01152186951284154, 680: 0.38060646871387765, 681: 0.4515349917936508, 682: -0.427482307537372, 683: -0.01822006446899501, 684: -0.1602321676400383, 685: -0.1305115409159496, 686: 0.15124419163863298, 687: 0.272807692580037, 688: 0.21657338111978547, 689: -1.2139151659350684, 690: 0.44577735133286966, 691: -0.049403763579415026, 692: 0.1672990661436627, 693: -0.7519925786909046, 694: 0.1707200505775833, 695: -0.2920303659531378, 696: 0.47108488344277444, 697: -0.10668172665925335, 698: -0.07018844720877701, 699: 0.34473522769741016, 700: 0.30379296293167585, 701: -0.2060847601602846, 702: -0.385200310249285, 703: 0.20474424558822374, 704: 0.19442472330209615, 705: 0.08845369584616337, 706: 0.26460840487448145, 707: -0.2284722909510032, 708: 0.00644872813561751, 709: 0.4160226902085085, 710: 0.5804647615102498, 711: 0.041054853007568774, 712: -0.29075598100314315, 713: 0.05756334348848975, 714: 0.133168301151027, 715: -0.26808773770937927, 716: 0.6478265700146927, 717: 0.37695985835122947, 718: 0.08437721846649915, 719: 0.04140284202035009, 720: 0.3949389480329346, 721: 0.23217749683843272, 722: 0.46622393045999594, 723: 0.4135740969101339, 724: 0.2699784976181132, 725: 0.7819999272274698, 726: 0.9725111383489833, 727: 0.2287246155349697, 728: -0.1700951994157722, 729: -1.4235957156257222, 730: 0.022194700562729888, 731: 0.955570187700348, 732: 0.346563506151722, 733: 0.01666756003200617, 734: -1.576280934207272, 735: -0.6664269167652112, 736: 0.8655785032531623, 737: 0.25688455124989207, 738: 0.5522612304760768, 739: 0.042350094283088134, 740: -0.5621276455440868, 741: 0.4651448387135762, 742: 0.5232425704493534, 743: 0.26290902681104156, 744: -0.010953871229374967, 745: -0.28484103006915984, 746: -0.19926136833269587, 747: 0.4138259749120214, 748: -0.11362909929713501, 749: -0.4980353391312193, 750: 0.05650440194057509, 751: -0.19021508511109858, 752: -0.009993828063861988, 753: -0.017668348083534534, 754: 0.32969987727877337, 755: 0.22366994806300916, 756: -0.044706907447453106, 757: 0.043505306804700355, 758: -0.1469152663027278, 759: 0.13722215757849618, 760: -0.01723054399749105, 761: -0.6017409180943784, 762: -0.21165322118281651, 763: 0.6044882282483384, 764: -1.2482565501101133, 765: -0.3143520325813273, 766: 0.19079971997379017, 767: -0.3337868551447628, 768: 0.559932857332264, 769: 0.019322350106686665, 770: 0.3451625685075466, 771: 0.1630590290975673, 772: 0.3709292535961063, 773: 0.10673025784980747, 774: 0.0, 775: 0.09756770810259428, 776: 0.0, 777: 0.1399021532230049, 778: 0.06249670027679663, 779: 0.6245967162385384, 780: 0.0, 781: 0.0, 782: 0.008717547631692135, 783: 0.0, 784: 0.18600618526299373, 785: 0.9275031554587729, 786: 0.6196354472763506, 787: 0.2371771755616079, 788: 0.0, 789: 0.6978747461095787, 790: 0.0, 791: 0.08085521121544328, 792: 0.15824971110737424, 793: 0.0, 794: 0.13075247033675585, 795: 0.0, 796: 0.2018045841901913, 797: 0.4413299575151099, 798: 0.0, 799: 0.0, 800: 0.1911757950756855, 801: 0.5089526738581829, 802: 0.038428407185695145, 803: 0.5798273645573049, 804: 0.5042882284149088, 805: 0.5085208061823157, 806: 0.0, 807: 0.0, 808: 0.19113828278737865, 809: 0.0, 810: 0.0, 811: 0.263319902405629, 812: 0.15218724055930224, 813: 0.18315959743907995, 814: 0.0, 815: 0.6802061825769906, 816: 0.6756183311781799, 817: 0.3434869791349063, 818: 0.56947701649553, 819: 0.0, 820: 0.30098619612454564, 821: 0.0, 822: 0.0, 823: 0.7442019540695254, 824: 0.5563850653204351, 825: 0.26679791004671355, 826: 0.36259334378143154, 827: 0.0, 828: 0.718035685163168, 829: 0.0, 830: 0.0, 831: 0.0, 832: 0.641963771178244, 833: 0.0, 834: 0.0, 835: 0.03427498201887731, 836: 0.0, 837: 0.32320274607470384, 838: 0.0, 839: 0.8472386956283918, 840: 0.0, 841: 0.10850186314065563, 842: 0.0, 843: 0.04514083510777504, 844: 0.1468137988919724, 845: 0.03758628977919927, 846: 0.0, 847: 0.02094153852279028, 848: 0.0, 849: 0.32943731093201234, 850: 0.7555753462315463, 851: 0.0, 852: 0.03229794393483452, 853: 0.3207413772046045, 854: 0.3077210897263394, 855: 0.06166118453825927, 856: 0.5472282966213969, 857: 0.0, 858: 0.6232099034959847, 859: 0.0, 860: 0.10058825446666678, 861: 0.1925530663534129, 862: 0.0, 863: 0.0, 864: 0.13514094529504783, 865: 0.040698732441307645, 866: 0.9728774079200847, 867: 0.102982289072475, 868: 0.7064387331853232, 869: 0.05348943945170369, 870: 0.29569564939437, 871: 0.05640240304450482, 872: 0.0, 873: 0.0, 874: 0.0, 875: 0.0, 876: 0.0, 877: 0.293443180803036, 878: 0.6966331597495969, 879: 0.0, 880: 0.10365917230661977, 881: 0.5475985578608727, 882: 0.16076581913075005, 883: 0.0, 884: 0.4193929855575453, 885: 0.29193237580229253, 886: 0.027730720684207098, 887: 0.0, 888: 0.3029188025197115, 889: 0.0, 890: 0.0, 891: 0.0, 892: 0.5089791776226374, 893: 0.58531208529332, 894: 0.08876105207408509, 895: 0.4861193580903679, 896: 0.0928533721683201, 897: 0.0, 898: 0.9260115095728837, 899: 0.0, 900: 0.0, 901: 0.0, 902: 0.193077203915536, 903: 0.18488967180596944, 904: 0.31183893049338496, 905: 0.7112645718852565, 906: 0.0, 907: 0.012005005323396756, 908: 0.4746987918040965, 909: 0.2571317870979042, 910: 0.16776908747634997, 911: 0.1907531597299847, 912: 0.20081976219488715, 913: 0.46937609162185906, 914: 0.0, 915: 0.0, 916: 0.4343865041543517, 917: 0.0, 918: 0.29241301939890296, 919: 0.0, 920: 0.14687259879402678, 921: 0.2992883840642076, 922: 0.5873134142681155, 923: 0.014961656923096991, 924: 0.24212347975058024, 925: 0.4603362465229334, 926: 0.42954727350660016, 927: 0.0, 928: 0.7519142073341789, 929: 0.0, 930: 0.0, 931: 0.5174167611910483, 932: 0.0, 933: 0.035544611418218755, 934: 0.2851456889761576, 935: 0.0, 936: 0.38060646871387765, 937: 0.4515349917936508, 938: 0.0, 939: 0.0, 940: 0.0, 941: 0.0, 942: 0.15124419163863298, 943: 0.272807692580037, 944: 0.21657338111978547, 945: 0.0, 946: 0.44577735133286966, 947: 0.0, 948: 0.1672990661436627, 949: 0.0, 950: 0.1707200505775833, 951: 0.0, 952: 0.47108488344277444, 953: 0.0, 954: 0.0, 955: 0.34473522769741016, 956: 0.30379296293167585, 957: 0.0, 958: 0.0, 959: 0.20474424558822374, 960: 0.19442472330209615, 961: 0.08845369584616337, 962: 0.26460840487448145, 963: 0.0, 964: 0.00644872813561751, 965: 0.4160226902085085, 966: 0.5804647615102498, 967: 0.041054853007568774, 968: 0.0, 969: 0.05756334348848975, 970: 0.133168301151027, 971: 0.0, 972: 0.6478265700146927, 973: 0.37695985835122947, 974: 0.08437721846649915, 975: 0.04140284202035009, 976: 0.3949389480329346, 977: 0.23217749683843272, 978: 0.46622393045999594, 979: 0.4135740969101339, 980: 0.2699784976181132, 981: 0.7819999272274698, 982: 0.9725111383489833, 983: 0.2287246155349697, 984: 0.0, 985: 0.0, 986: 0.022194700562729888, 987: 0.955570187700348, 988: 0.346563506151722, 989: 0.01666756003200617, 990: 0.0, 991: 0.0, 992: 0.8655785032531623, 993: 0.25688455124989207, 994: 0.5522612304760768, 995: 0.042350094283087385, 996: 0.0, 997: 0.4651448387135762, 998: 0.5232425704493534, 999: 0.26290902681104156, 1000: 0.0, 1001: 0.0, 1002: 0.0, 1003: 0.4138259749120214, 1004: 0.0, 1005: 0.0, 1006: 0.05650440194057509, 1007: 0.0, 1008: 0.0, 1009: 0.0, 1010: 0.32969987727877337, 1011: 0.22366994806300916, 1012: 0.0, 1013: 0.043505306804700355, 1014: 0.0, 1015: 0.13722215757849618, 1016: 0.0, 1017: 0.0, 1018: 0.0, 1019: 0.6044882282483384, 1020: 0.0, 1021: 0.0, 1022: 0.19079971997379017, 1023: 0.0, 1024: 0.559932857332264, 1025: 0.019322350106686665, 1026: 0.3451625685075466, 1027: 0.1630590290975673, 1028: 0.3709292535961063, 1029: 0.1586959760099806, 1030: 0.3545585376732643, 1031: 0.3493389162908587, 1032: -0.27608288869732905, 1033: 0.00879479306522659, 1034: 0.015601855022147018, 1035: -0.31967889502552244, 1036: 0.4473839122383771, 1037: 0.39657164896980834, 1038: 0.24686177399837383, 1039: -0.43829737056337387, 1040: 0.3027026394865269, 1041: 0.2168285862384746, 1042: 0.19543876198048232, 1043: 0.1701787935185506, 1044: -0.08196036121996886, 1045: 0.038549158209992086, 1046: 0.5237776720815843, 1047: -0.4195506305967946, 1048: 0.05175575972814277, 1049: 0.24196081454158308, 1050: 0.32846720254541273, 1051: 0.07016527975775642, 1052: 0.3516642186168095, 1053: 0.25166840844237104, 1054: 0.16589766267007602, 1055: 0.12484603525568255, 1056: -0.005427671732971963, 1057: 0.17463738716496008, 1058: 0.18593871537920073, 1059: 0.48368891587206875, 1060: 0.06981911509243181, 1061: -0.08930062282253914, 1062: 0.2629209287138638, 1063: -0.13596478473936147, 1064: 0.3031810188834008, 1065: 0.1668100915566023, 1066: 0.23921376271208317, 1067: 0.28237996811808436, 1068: -0.20443060342192543, 1069: -0.2407525038431341, 1070: -0.3398864144579978, 1071: 0.09907629649538637, 1072: 0.17297351961306082, 1073: 0.5190941776074806, 1074: -0.06819963163757246, 1075: -0.15911308558412235, 1076: 0.3754376012193613, 1077: 0.3196696970889197, 1078: 0.22373704607828968, 1079: 0.26498673692514685, 1080: -0.029860053221025126, 1081: 0.15743957729549232, 1082: -0.021404742012885513, 1083: -0.33472059840370844, 1084: -0.12564310997043976, 1085: 0.35641089161105177, 1086: 0.18032148238199297, 1087: 0.25737978657798866, 1088: 0.4798258337001987, 1089: 0.5063911080360413, 1090: 0.10274769981637592, 1091: -0.04951859751887655, 1092: 0.17471482269674718, 1093: 0.3083301757246687, 1094: 0.04950594902893651, 1095: 0.4844184438319719, 1096: 0.2432114310733159, 1097: 0.07196480129407598, 1098: 0.23963712165862705, 1099: -0.15053422744800873, 1100: -0.301982893761023, 1101: -0.21345515744323848, 1102: 0.5395018228014327, 1103: -0.4050499587253725, 1104: 0.38141072496146944, 1105: 0.4679284874668301, 1106: 0.46956223623525, 1107: 0.27882525905453676, 1108: 0.31568215010458345, 1109: -0.11740848079763994, 1110: -0.34843270033700285, 1111: 0.4658265375740501, 1112: 0.08147163811703867, 1113: 0.04483440075803814, 1114: 0.0025923306651257014, 1115: 0.19535327341723133, 1116: -0.2569450244289406, 1117: 0.07361230356195406, 1118: 0.2445744363392837, 1119: -0.15729901149533895, 1120: 0.2838132553273886, 1121: 0.3584753829106614, 1122: 0.4504520278893852, 1123: 0.22454280059646214, 1124: 0.26346976442999137, 1125: 0.3822988957556435, 1126: 0.15235637950502037, 1127: -0.0008455087545770588, 1128: 0.2071551411034767, 1129: 0.23727579754799505, 1130: 0.21022717010308695, 1131: 0.18419019710845333, 1132: -0.1085643610393162, 1133: 0.37307153088101497, 1134: -0.14652395404309113, 1135: 0.14940400534699672, 1136: 0.25647483409548866, 1137: 0.48246393004289745, 1138: -0.3180007357454788, 1139: 0.16737819986729857, 1140: 0.16154192513018983, 1141: 0.3035304592586772, 1142: -0.2239180286736053, 1143: 0.23813099395071263, 1144: 0.37581368707717183, 1145: 0.11052275068776732, 1146: 0.38869101436524855, 1147: 0.07698217419950265, 1148: 0.056424062588024, 1149: 0.13883533294679995, 1150: 0.5252580533962596, 1151: 0.43201314226217286, 1152: -0.2130561582528008, 1153: 0.3380171488425225, 1154: 0.31604546308517395, 1155: 0.15978467325464799, 1156: 0.1872359050570455, 1157: -0.045564481879616515, 1158: 0.508314396758967, 1159: -0.4322926438300023, 1160: 0.17930106889840375, 1161: 0.34896932422172144, 1162: 0.25985575256262833, 1163: 0.013199422085768946, 1164: 0.38362822256462836, 1165: -0.0376675679531147, 1166: 0.36778943341994613, 1167: 0.0905160822669949, 1168: 0.21009278955071253, 1169: -0.18515194952487946, 1170: 0.21582541753354656, 1171: 0.19603789629876311, 1172: 0.37015115210348765, 1173: 0.24811955178503897, 1174: 0.16508854551418536, 1175: 0.3151617185175607, 1176: 0.2342203589160411, 1177: 0.2026094895748906, 1178: -0.24579173872455407, 1179: 0.44384842616663644, 1180: 0.3010238321968299, 1181: 0.09777368185593545, 1182: 0.14308659493853415, 1183: 0.03401335395049119, 1184: 0.2894734998047299, 1185: 0.09566743269151755, 1186: 0.312947729565954, 1187: 0.42153968209363335, 1188: 0.01682694138680378, 1189: -0.29328117253377234, 1190: 0.17578826236423986, 1191: -0.9940416428718768, 1192: -0.025984856807128878, 1193: -0.5066337329534212, 1194: 0.6322388572181309, 1195: 0.09660637811512657, 1196: 0.5027825807039367, 1197: -0.24125032419291184, 1198: 0.1861242995138592, 1199: 0.30802686010491837, 1200: -0.5253392663919709, 1201: 0.47250084255127994, 1202: 0.18678049888427245, 1203: 0.17679853205521023, 1204: -0.16556610009041742, 1205: 0.23690175039074013, 1206: -0.30046427295066735, 1207: 0.20850315465679484, 1208: 0.11781636229916256, 1209: 0.5982219778176746, 1210: -0.010278718108561997, 1211: 0.08600176179206012, 1212: 0.25585868569803916, 1213: -0.036760895025953824, 1214: -0.5353852606455155, 1215: 0.34865737272884406, 1216: 0.09636902864300682, 1217: 0.304737698807947, 1218: -0.041983975984797126, 1219: 0.2638059539254255, 1220: 0.08073259360443727, 1221: -0.205902800933077, 1222: 0.019931203067586355, 1223: 0.3380927749268807, 1224: 0.3255207103958974, 1225: 0.34185760353254524, 1226: -0.3155288201445782, 1227: 0.23524378657099795, 1228: 0.02939153158610633, 1229: 0.29229109391979813, 1230: 0.029860618931669965, 1231: -0.050475743219671104, 1232: 0.5049233119289178, 1233: -0.09303030128900196, 1234: 0.2485289294866313, 1235: -0.4399257359786107, 1236: 0.6432947560074372, 1237: -0.33085482051058646, 1238: 0.3713456981837976, 1239: -0.0007814067057419112, 1240: 0.2194629827999452, 1241: 0.12044747612484955, 1242: 0.3838639261165152, 1243: 0.3424362443726812, 1244: -0.5284312118906047, 1245: 0.4152532533881592, 1246: 0.19729228199486432, 1247: 0.1414819906659636, 1248: 0.0009805764857379988, 1249: 0.03234971877353808, 1250: 0.33578809375830326, 1251: 0.012119147017955035, 1252: -0.28361571383851136, 1253: -0.09382064167993619, 1254: 0.07930685145830088, 1255: -0.5596286603673711, 1256: -0.17043098133471116, 1257: 0.2659035370893369, 1258: -0.4720866154002912, 1259: 0.018795318220420968, 1260: 0.45508737412852, 1261: -0.059605177669846576, 1262: -0.49494439625776815, 1263: 0.2573989957009259, 1264: 0.22393731245725235, 1265: 0.3393507568068132, 1266: -0.14895423486476367, 1267: 0.3350781370241873, 1268: 0.1344725521232586, 1269: 0.16915956462259163, 1270: 0.2650046563149763, 1271: 0.08250203681577128, 1272: 0.26251625701110787, 1273: 0.25799777736121454, 1274: 0.14464131343468156, 1275: -0.18825700317213345, 1276: 0.07386228963738986, 1277: 0.4072132460821407, 1278: 0.2694736998392423, 1279: -0.0382310693907556, 1280: 0.042106404218607514, 1281: -0.023656997318414676, 1282: 0.29962139795619863, 1283: 0.07002945588587722, 1284: 0.24897279272401684, 1285: 0.1586959760099806, 1286: 0.3545585376732643, 1287: 0.3493389162908587, 1288: 0.0, 1289: 0.00879479306522659, 1290: 0.015601855022147018, 1291: 0.0, 1292: 0.4473839122383771, 1293: 0.39657164896980834, 1294: 0.24686177399837383, 1295: 0.0, 1296: 0.3027026394865269, 1297: 0.2168285862384746, 1298: 0.19543876198048232, 1299: 0.1701787935185506, 1300: 0.0, 1301: 0.038549158209992086, 1302: 0.5237776720815843, 1303: 0.0, 1304: 0.05175575972814277, 1305: 0.24196081454158308, 1306: 0.32846720254541273, 1307: 0.07016527975775642, 1308: 0.3516642186168095, 1309: 0.25166840844237104, 1310: 0.16589766267007602, 1311: 0.12484603525568255, 1312: 0.0, 1313: 0.17463738716496008, 1314: 0.18593871537920073, 1315: 0.48368891587206875, 1316: 0.06981911509243181, 1317: 0.0, 1318: 0.2629209287138638, 1319: 0.0, 1320: 0.3031810188834008, 1321: 0.1668100915566023, 1322: 0.23921376271208317, 1323: 0.28237996811808436, 1324: 0.0, 1325: 0.0, 1326: 0.0, 1327: 0.09907629649538637, 1328: 0.17297351961306082, 1329: 0.5190941776074806, 1330: 0.0, 1331: 0.0, 1332: 0.3754376012193613, 1333: 0.3196696970889197, 1334: 0.22373704607828968, 1335: 0.26498673692514685, 1336: 0.0, 1337: 0.15743957729549232, 1338: 0.0, 1339: 0.0, 1340: 0.0, 1341: 0.35641089161105177, 1342: 0.18032148238199297, 1343: 0.25737978657798866, 1344: 0.4798258337001987, 1345: 0.5063911080360413, 1346: 0.10274769981637592, 1347: 0.0, 1348: 0.17471482269674718, 1349: 0.3083301757246687, 1350: 0.04950594902893651, 1351: 0.4844184438319719, 1352: 0.2432114310733159, 1353: 0.07196480129407598, 1354: 0.23963712165862705, 1355: 0.0, 1356: 0.0, 1357: 0.0, 1358: 0.5395018228014327, 1359: 0.0, 1360: 0.38141072496146944, 1361: 0.4679284874668301, 1362: 0.46956223623525, 1363: 0.27882525905453676, 1364: 0.31568215010458345, 1365: 0.0, 1366: 0.0, 1367: 0.4658265375740501, 1368: 0.08147163811703867, 1369: 0.04483440075803814, 1370: 0.0025923306651257014, 1371: 0.19535327341723133, 1372: 0.0, 1373: 0.07361230356195406, 1374: 0.2445744363392837, 1375: 0.0, 1376: 0.2838132553273886, 1377: 0.3584753829106614, 1378: 0.4504520278893852, 1379: 0.22454280059646214, 1380: 0.26346976442999137, 1381: 0.3822988957556435, 1382: 0.15235637950502037, 1383: 0.0, 1384: 0.2071551411034767, 1385: 0.23727579754799505, 1386: 0.21022717010308695, 1387: 0.18419019710845333, 1388: 0.0, 1389: 0.37307153088101497, 1390: 0.0, 1391: 0.14940400534699672, 1392: 0.25647483409548866, 1393: 0.48246393004289745, 1394: 0.0, 1395: 0.16737819986729857, 1396: 0.16154192513018983, 1397: 0.3035304592586772, 1398: 0.0, 1399: 0.23813099395071263, 1400: 0.37581368707717183, 1401: 0.11052275068776732, 1402: 0.38869101436524855, 1403: 0.07698217419950265, 1404: 0.05642406258802394, 1405: 0.13883533294679995, 1406: 0.5252580533962596, 1407: 0.43201314226217286, 1408: 0.0, 1409: 0.3380171488425225, 1410: 0.31604546308517456, 1411: 0.15978467325464799, 1412: 0.1872359050570455, 1413: 0.0, 1414: 0.508314396758967, 1415: 0.0, 1416: 0.17930106889840375, 1417: 0.34896932422172144, 1418: 0.25985575256262833, 1419: 0.013199422085768946, 1420: 0.38362822256462836, 1421: 0.0, 1422: 0.36778943341994613, 1423: 0.0905160822669949, 1424: 0.21009278955071253, 1425: 0.0, 1426: 0.21582541753354656, 1427: 0.19603789629876311, 1428: 0.37015115210348765, 1429: 0.24811955178503897, 1430: 0.16508854551418536, 1431: 0.3151617185175607, 1432: 0.2342203589160411, 1433: 0.2026094895748906, 1434: 0.0, 1435: 0.44384842616663644, 1436: 0.3010238321968299, 1437: 0.09777368185593545, 1438: 0.14308659493853415, 1439: 0.03401335395049119, 1440: 0.2894734998047299, 1441: 0.09566743269151755, 1442: 0.312947729565954, 1443: 0.42153968209363335, 1444: 0.01682694138680378, 1445: 0.0, 1446: 0.17578826236423986, 1447: 0.0, 1448: 0.0, 1449: 0.0, 1450: 0.6322388572181309, 1451: 0.09660637811512657, 1452: 0.5027825807039367, 1453: 0.0, 1454: 0.1861242995138592, 1455: 0.30802686010491837, 1456: 0.0, 1457: 0.47250084255127994, 1458: 0.18678049888427245, 1459: 0.17679853205521023, 1460: 0.0, 1461: 0.23690175039074013, 1462: 0.0, 1463: 0.20850315465679484, 1464: 0.11781636229916256, 1465: 0.5982219778176746, 1466: 0.0, 1467: 0.08600176179206012, 1468: 0.25585868569803916, 1469: 0.0, 1470: 0.0, 1471: 0.34865737272884406, 1472: 0.09636902864300682, 1473: 0.304737698807947, 1474: 0.0, 1475: 0.2638059539254255, 1476: 0.08073259360443727, 1477: 0.0, 1478: 0.019931203067586355, 1479: 0.3380927749268807, 1480: 0.3255207103958974, 1481: 0.34185760353254524, 1482: 0.0, 1483: 0.23524378657099795, 1484: 0.02939153158610633, 1485: 0.29229109391979813, 1486: 0.029860618931669965, 1487: 0.0, 1488: 0.5049233119289178, 1489: 0.0, 1490: 0.2485289294866313, 1491: 0.0, 1492: 0.6432947560074372, 1493: 0.0, 1494: 0.3713456981837976, 1495: 0.0, 1496: 0.2194629827999452, 1497: 0.12044747612484955, 1498: 0.3838639261165152, 1499: 0.3424362443726812, 1500: 0.0, 1501: 0.4152532533881592, 1502: 0.19729228199486432, 1503: 0.1414819906659636, 1504: 0.0009805764857379988, 1505: 0.03234971877353808, 1506: 0.33578809375830326, 1507: 0.012119147017955035, 1508: 0.0, 1509: 0.0, 1510: 0.07930685145830088, 1511: 0.0, 1512: 0.0, 1513: 0.2659035370893369, 1514: 0.0, 1515: 0.018795318220420968, 1516: 0.45508737412852, 1517: 0.0, 1518: 0.0, 1519: 0.2573989957009259, 1520: 0.22393731245725235, 1521: 0.3393507568068132, 1522: 0.0, 1523: 0.3350781370241873, 1524: 0.1344725521232586, 1525: 0.16915956462259163, 1526: 0.2650046563149763, 1527: 0.08250203681577128, 1528: 0.26251625701110787, 1529: 0.25799777736121454, 1530: 0.14464131343468156, 1531: 0.0, 1532: 0.07386228963738986, 1533: 0.4072132460821407, 1534: 0.2694736998392423, 1535: 0.0, 1536: 0.042106404218607514, 1537: 0.0, 1538: 0.29962139795619863, 1539: 0.07002945588587722, 1540: 0.24897279272401684, 1541: 1.210201327984187}\n",
            "stats: <maraboupy.MarabouCore.Statistics object at 0x7cf3701cb170>\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}